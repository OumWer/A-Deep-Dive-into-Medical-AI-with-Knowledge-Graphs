{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c676239b",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b80c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional, Tuple, Set\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from neo4j import GraphDatabase\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f1283",
   "metadata": {},
   "source": [
    "# CONFIGURATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8b7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j Configuration\n",
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"\n",
    "\n",
    "# Pipeline Configuration\n",
    "MAX_NODES = 1500\n",
    "TOP_K = 5\n",
    "SIM_THRESHOLD = 0.6\n",
    "EXACT_MATCH_THRESHOLD = 0.9\n",
    "LLM_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "MAX_PATH_LENGTH = 4  # Maximum relationship hops to search\n",
    "MAX_PATHS_PER_PAIR = 5  # Increased for better pruning\n",
    "TOP_PATHS_FOR_PRUNING = 3  # Top paths to consider for LLM pruning\n",
    "\n",
    "# Medical Entity types\n",
    "ENTITY_TYPES = [\n",
    "    \"disease\",\n",
    "    \"drug\"\n",
    "]\n",
    "# Removed \"Embedding\" as it might be a category mistake\n",
    "\n",
    "# Entity Property Schemas\n",
    "# Entity Property Schemas adapted to biomedical entity types\n",
    "ENTITY_PROPERTY_SCHEMAS = {\n",
    "    \"disease\": {\n",
    "        \"properties\": [\n",
    "            \"SNOMEDCT_US_definition\",\n",
    "            \"mayo_causes\",\n",
    "            \"mayo_complications\",\n",
    "            \"mayo_prevention\",\n",
    "            \"mayo_risk_factors\",\n",
    "            \"mayo_see_doc\",\n",
    "            \"mayo_symptoms\",\n",
    "            \"mondo_definitions\",\n",
    "            \"node_id\",\n",
    "            \"node_index\",\n",
    "            \"node_name\",\n",
    "            \"node_source\",\n",
    "            \"orphanet_clinical_description\",\n",
    "            \"orphanet_definition\",\n",
    "            \"orphanet_epidemiology\",\n",
    "            \"orphanet_management_and_treatment\",\n",
    "            \"orphanet_prevalence\",\n",
    "            \"umls_descriptions\"\n",
    "        ],\n",
    "        \"primary_keys\": [\"node_id\", \"node_name\"],\n",
    "        \"display_properties\": [\n",
    "            \"node_name\",\n",
    "            \"mondo_definitions\",\n",
    "            \"mayo_symptoms\",\n",
    "            \"orphanet_prevalence\"\n",
    "        ]\n",
    "    },\n",
    "    \"drug\": {\n",
    "        \"properties\": [\n",
    "            \"atc_4\",\n",
    "            \"category\",\n",
    "            \"clogp\",\n",
    "            \"description\",\n",
    "            \"group\",\n",
    "            \"half_life\",\n",
    "            \"indication\",\n",
    "            \"mechanism_of_action\",\n",
    "            \"molecular_weight\",\n",
    "            \"node_id\",\n",
    "            \"node_index\",\n",
    "            \"node_name\",\n",
    "            \"node_source\",\n",
    "            \"pathway\",\n",
    "            \"pharmacodynamics\",\n",
    "            \"protein_binding\",\n",
    "            \"state\",\n",
    "            \"tpsa\"\n",
    "        ],\n",
    "        \"primary_keys\": [\"node_id\", \"node_name\"],\n",
    "        \"display_properties\": [\n",
    "            \"node_name\",\n",
    "            \"description\",\n",
    "            \"indication\",\n",
    "            \"mechanism_of_action\",\n",
    "            \"category\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# REVISED Property weightings for similarity\n",
    "PROPERTY_WEIGHTS = {\n",
    "    \"exact_primary_key\": 10.0,      # Very high for exact primary key matches\n",
    "    \"exact_display_property\": 5.0,   # High for exact display property matches\n",
    "    \"contains_primary_key\": 3.0,     # Good for contains matches\n",
    "    \"contains_display_property\": 2.0, # Medium for contains matches\n",
    "    \"other_property_match\": 1.0,     # Low for other properties\n",
    "    \"name_exact\": 8.0,               # High for exact name matches\n",
    "    \"name_contains\": 4.0             # Medium for name contains\n",
    "}\n",
    "\n",
    "# Entity examples for better prompting\n",
    "# Entity examples for biomedical entity types\n",
    "ENTITY_EXAMPLES = {\n",
    "    \"disease\": [\n",
    "        \"folliculotropic mycosis fungoides\",\n",
    "        \"localized pagetoid reticulosis\", \n",
    "        \"erythema multiforme\",\n",
    "        \"classic Hodgkin lymphoma, lymphocyte-rich type\",\n",
    "        \"Hodgkin's paragranuloma\",\n",
    "        \"lymphosarcoma\",\n",
    "        \"hairy cell leukemia variant\"\n",
    "    ],\n",
    "    \"drug\": [\n",
    "        \"Diethylstilbestrol\",\n",
    "        \"Liothyronine\",\n",
    "        \"Levothyroxine\",\n",
    "        \"Hydrocortisone cypionate\",\n",
    "        \"Hydrocortisone phosphate\",\n",
    "        \"Hydrocortisone probutate\", \n",
    "        \"Hydrocortisone valerate\",\n",
    "        \"Prednisolone phosphate\",\n",
    "        \"Prednisolone acetate\",\n",
    "        \"Betamethasone phosphate\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56e9e6a",
   "metadata": {},
   "source": [
    "# NEO4J CONNECTION & KG LOADING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095b3ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading disease and drug nodes from knowledge graph...\n",
      "ðŸ“Š Total disease and drug nodes in KG: 25037\n",
      "ðŸ“¥ Loaded 25037 disease/drug nodes from Neo4j query\n",
      "\n",
      "ðŸ“Š Label Distribution (disease/drug):\n",
      "   disease: 17080\n",
      "   drug: 7957\n",
      "\n",
      "ðŸ“Š Entity Type Distribution:\n",
      "   Disease: 17080 (68.2%)\n",
      "   Drug: 7957 (31.8%)\n",
      "\n",
      "ðŸ“ Average property text length: 268 characters\n",
      "âœ… Successfully loaded 25037 disease/drug nodes from knowledge graph\n",
      "\n",
      "ðŸ“‹ Sample disease/drug nodes loaded:\n",
      "  1. drug-induced dyskinesia (disease) - Props: 14\n",
      "     Preview: drug-induced dyskinesia 6732 ['Abnormal movements, including hyperkinesis; hypok...\n",
      "  2. hyperemesis gravidarum (disease) (disease) - Props: 6\n",
      "     Preview: hyperemesis gravidarum (disease) 6791 ['Severe, intractable vomiting during preg...\n",
      "  3. torsades de pointes (disease) - Props: 12\n",
      "     Preview: torsades de pointes 5478 ['A malignant form of polymorphic ventricular tachycard...\n",
      "  4. focal hand dystonia (disease) - Props: 15\n",
      "     Preview: focal hand dystonia 482 ['A focal dystonia that affects a single muscle or small...\n",
      "  5. tinea pedis (disease) - Props: 15\n",
      "     Preview: tinea pedis 5984 ['Dermatological pruritic lesion in the feet, caused by Trichop...\n",
      "\n",
      "ðŸ’¾ Summary saved to disease_drug_nodes_summary.json\n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    NEO4J_URI,\n",
    "    auth=(NEO4J_USER, NEO4J_PASSWORD)\n",
    ")\n",
    "\n",
    "# Global variables to store statistics\n",
    "label_counts_global = defaultdict(int)\n",
    "type_counts_global = defaultdict(int)\n",
    "\n",
    "def load_kg_nodes_with_properties() -> List[Dict]:\n",
    "    \"\"\"Load ONLY disease and drug nodes from the KG and combine all properties for embeddings.\"\"\"\n",
    "    global label_counts_global, type_counts_global\n",
    "    \n",
    "    with driver.session() as s:\n",
    "        # Count disease and drug nodes\n",
    "        count_result = s.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE any(label IN labels(n) WHERE label IN ['disease', 'drug'])\n",
    "        RETURN count(n) AS total_disease_drug_nodes\n",
    "        \"\"\").data()\n",
    "        \n",
    "        total_disease_drug_nodes = count_result[0][\"total_disease_drug_nodes\"]\n",
    "        print(f\"ðŸ“Š Total disease and drug nodes in KG: {total_disease_drug_nodes}\")\n",
    "        \n",
    "        # Load ONLY disease and drug nodes with properties\n",
    "        nodes = s.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE any(label IN labels(n) WHERE label IN ['disease', 'drug'])\n",
    "        RETURN elementId(n) AS node_id, labels(n) AS labels, properties(n) AS properties\n",
    "        \"\"\").data()\n",
    "    \n",
    "    print(f\"ðŸ“¥ Loaded {len(nodes)} disease/drug nodes from Neo4j query\")\n",
    "    \n",
    "    enhanced_nodes = []\n",
    "    label_counts_local = defaultdict(int)\n",
    "    type_counts_local = defaultdict(int)\n",
    "    \n",
    "    for node in nodes:\n",
    "        props = dict(node[\"properties\"])\n",
    "        labels = node[\"labels\"]\n",
    "        \n",
    "        # Count label frequencies\n",
    "        for label in labels:\n",
    "            label_counts_local[label] += 1\n",
    "        \n",
    "        # Create combined text from ALL property values\n",
    "        combined_text = \" \".join(str(v) for v in props.values() if v is not None)\n",
    "        \n",
    "        # Determine best node name - prioritize node_name property\n",
    "        node_name = None\n",
    "        \n",
    "        # First, check for node_name property (most reliable)\n",
    "        if \"node_name\" in props and props[\"node_name\"]:\n",
    "            node_name = str(props[\"node_name\"])\n",
    "        else:\n",
    "            # Try other name candidates\n",
    "            name_candidates = [\n",
    "                \"name\", \"Name\", \"NAME\",\n",
    "                \"description\", \"Description\",\n",
    "                \"SNOMEDCT_US_definition\", \"mondo_definitions\",\n",
    "                \"indication\", \"mechanism_of_action\",\n",
    "                \"title\", \"Title\", \"label\", \"Label\"\n",
    "            ]\n",
    "            \n",
    "            for prop in name_candidates:\n",
    "                if prop in props and props[prop]:\n",
    "                    node_name = str(props[prop])\n",
    "                    # Take only first 100 chars to avoid huge text\n",
    "                    if len(node_name) > 100:\n",
    "                        node_name = node_name[:100] + \"...\"\n",
    "                    break\n",
    "        \n",
    "        # Fallback: use first property value\n",
    "        if not node_name and props:\n",
    "            for value in props.values():\n",
    "                if value is not None:\n",
    "                    node_name = str(value)\n",
    "                    if len(node_name) > 100:\n",
    "                        node_name = node_name[:100] + \"...\"\n",
    "                    break\n",
    "        \n",
    "        # Final fallback\n",
    "        if not node_name:\n",
    "            node_name = f\"Node_{len(enhanced_nodes)+1}\"\n",
    "        \n",
    "        # Determine entity type based on labels\n",
    "        entity_type = \"Unknown\"\n",
    "        \n",
    "        # Check if node has disease or drug label\n",
    "        for label in labels:\n",
    "            if label.lower() in ['disease', 'drug']:\n",
    "                entity_type = label.lower()\n",
    "                break\n",
    "        \n",
    "        # If still unknown, try to infer from properties\n",
    "        if entity_type == \"Unknown\":\n",
    "            # Check for disease-specific properties\n",
    "            disease_props = [\"SNOMEDCT_US_definition\", \"mondo_definitions\", \"mayo_symptoms\", \"orphanet_definition\"]\n",
    "            if any(prop in props for prop in disease_props):\n",
    "                entity_type = \"disease\"\n",
    "            # Check for drug-specific properties\n",
    "            elif any(prop in props for prop in [\"mechanism_of_action\", \"atc_4\", \"indication\", \"pharmacodynamics\"]):\n",
    "                entity_type = \"drug\"\n",
    "            else:\n",
    "                # Fuzzy label matching\n",
    "                label_str = \" \".join(labels).lower()\n",
    "                if \"disease\" in label_str or \"disorder\" in label_str or \"syndrome\" in label_str:\n",
    "                    entity_type = \"disease\"\n",
    "                elif \"drug\" in label_str or \"compound\" in label_str or \"medication\" in label_str:\n",
    "                    entity_type = \"drug\"\n",
    "                else:\n",
    "                    # Default to first label\n",
    "                    entity_type = labels[0] if labels else \"Unknown\"\n",
    "        \n",
    "        # Skip if not disease or drug (shouldn't happen with our query, but just in case)\n",
    "        if entity_type not in [\"disease\", \"drug\"]:\n",
    "            continue\n",
    "        \n",
    "        # Count entity types\n",
    "        type_counts_local[entity_type] += 1\n",
    "        \n",
    "        # Create enhanced property text for better embeddings\n",
    "        property_text = node_name\n",
    "        \n",
    "        # Use schema-based property enhancement\n",
    "        if entity_type in ENTITY_PROPERTY_SCHEMAS:\n",
    "            schema = ENTITY_PROPERTY_SCHEMAS[entity_type]\n",
    "            \n",
    "            # Add primary keys to property text\n",
    "            for prop in schema.get(\"primary_keys\", []):\n",
    "                if prop in props and props[prop]:\n",
    "                    prop_value = str(props[prop])\n",
    "                    if prop_value and prop_value.lower() not in property_text.lower():\n",
    "                        property_text += f\" {prop_value}\"\n",
    "            \n",
    "            # Add display properties to property text\n",
    "            for prop in schema.get(\"display_properties\", []):\n",
    "                if prop in props and props[prop]:\n",
    "                    prop_value = str(props[prop])\n",
    "                    if prop_value and prop_value.lower() not in property_text.lower():\n",
    "                        property_text += f\" {prop_value}\"\n",
    "        else:\n",
    "            # For unknown schema, add important properties\n",
    "            important_props = [\"description\", \"definition\", \"indication\", \"symptoms\", \"mechanism\"]\n",
    "            added_count = 0\n",
    "            for prop in important_props:\n",
    "                if prop in props and props[prop] and added_count < 3:\n",
    "                    prop_value = str(props[prop])\n",
    "                    if prop_value and prop_value.lower() not in property_text.lower():\n",
    "                        property_text += f\" {prop_value}\"\n",
    "                        added_count += 1\n",
    "        \n",
    "        # Limit property text length to avoid huge embeddings\n",
    "        if len(property_text) > 500:\n",
    "            property_text = property_text[:500] + \"...\"\n",
    "        \n",
    "        enhanced_nodes.append({\n",
    "            \"node_id\": str(node[\"node_id\"]),\n",
    "            \"node_name\": node_name,\n",
    "            \"labels\": labels,\n",
    "            \"entity_type\": entity_type,\n",
    "            \"properties\": props,\n",
    "            \"property_keys\": list(props.keys()),\n",
    "            \"combined_text\": combined_text.strip(),\n",
    "            \"property_text\": property_text.strip(),\n",
    "            \"text_length\": len(property_text.strip())\n",
    "        })\n",
    "    \n",
    "    # Update global statistics\n",
    "    for label, count in label_counts_local.items():\n",
    "        label_counts_global[label] += count\n",
    "    \n",
    "    for entity_type, count in type_counts_local.items():\n",
    "        type_counts_global[entity_type] += count\n",
    "    \n",
    "    # Print label distribution\n",
    "    print(f\"\\nðŸ“Š Label Distribution (disease/drug):\")\n",
    "    for label, count in sorted(label_counts_local.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   {label}: {count}\")\n",
    "    \n",
    "    # Print entity type distribution\n",
    "    print(f\"\\nðŸ“Š Entity Type Distribution:\")\n",
    "    \n",
    "    # Count and display disease vs drug distribution\n",
    "    disease_count = type_counts_local.get(\"disease\", 0)\n",
    "    drug_count = type_counts_local.get(\"drug\", 0)\n",
    "    total_filtered = disease_count + drug_count\n",
    "    \n",
    "    if total_filtered > 0:\n",
    "        print(f\"   Disease: {disease_count} ({disease_count/total_filtered*100:.1f}%)\")\n",
    "        print(f\"   Drug: {drug_count} ({drug_count/total_filtered*100:.1f}%)\")\n",
    "    \n",
    "    # Print other entity types if any\n",
    "    for entity_type, count in sorted(type_counts_local.items(), key=lambda x: x[1], reverse=True):\n",
    "        if entity_type not in [\"disease\", \"drug\"]:\n",
    "            print(f\"   {entity_type}: {count}\")\n",
    "    \n",
    "    # Print text length statistics\n",
    "    if enhanced_nodes:\n",
    "        avg_length = sum(node[\"text_length\"] for node in enhanced_nodes) / len(enhanced_nodes)\n",
    "        print(f\"\\nðŸ“ Average property text length: {avg_length:.0f} characters\")\n",
    "    \n",
    "    return enhanced_nodes\n",
    "\n",
    "# Load KG nodes\n",
    "print(\"ðŸ”„ Loading disease and drug nodes from knowledge graph...\")\n",
    "KG_NODES = load_kg_nodes_with_properties()\n",
    "print(f\"âœ… Successfully loaded {len(KG_NODES)} disease/drug nodes from knowledge graph\")\n",
    "\n",
    "if len(KG_NODES) == 0:\n",
    "    print(\"âŒ ERROR: No disease or drug nodes loaded!\")\n",
    "    print(\"   Possible reasons:\")\n",
    "    print(\"   1. Check Neo4j connection and credentials\")\n",
    "    print(\"   2. Verify nodes have 'disease' or 'drug' labels\")\n",
    "    print(\"   3. Check if database contains disease/drug data\")\n",
    "    exit(1)\n",
    "\n",
    "# Use both combined_text and property_text for different purposes\n",
    "KG_TEXTS = [node[\"property_text\"] for node in KG_NODES]\n",
    "print(f\"\\nðŸ“‹ Sample disease/drug nodes loaded:\")\n",
    "for i, node in enumerate(KG_NODES[:5]):\n",
    "    entity_type = node.get('entity_type', 'Unknown')\n",
    "    props_count = len(node['properties'])\n",
    "    name_preview = node['node_name'][:60] + \"...\" if len(node['node_name']) > 60 else node['node_name']\n",
    "    text_preview = node['property_text'][:80] + \"...\" if len(node['property_text']) > 80 else node['property_text']\n",
    "    print(f\"  {i+1}. {name_preview} ({entity_type}) - Props: {props_count}\")\n",
    "    print(f\"     Preview: {text_preview}\")\n",
    "\n",
    "# Optional: Save summary to file - using the GLOBAL variables\n",
    "import json\n",
    "with open(\"disease_drug_nodes_summary.json\", \"w\") as f:\n",
    "    summary = {\n",
    "        \"total_nodes\": len(KG_NODES),\n",
    "        \"entity_type_counts\": dict(type_counts_global),\n",
    "        \"label_counts\": dict(label_counts_global),\n",
    "        \"sample_nodes\": KG_NODES[:10]\n",
    "    }\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "print(f\"\\nðŸ’¾ Summary saved to disease_drug_nodes_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18ceb7",
   "metadata": {},
   "source": [
    "# ENHANCED EMBEDDINGS & SIMILARITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3157712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Loading embedding model...\n",
      "ðŸ”„ Encoding 25037 KG nodes with enhanced property text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7402a6e2f9ce4b698ab9d6f4f6a54031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… KG embeddings computed for 25037 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ”„ Loading embedding model...\")\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(f\"ðŸ”„ Encoding {len(KG_TEXTS)} KG nodes with enhanced property text...\")\n",
    "\n",
    "# Batch encoding to handle memory better\n",
    "try:\n",
    "    KG_EMBEDDINGS = embedder.encode(KG_TEXTS, show_progress_bar=True, convert_to_numpy=True)\n",
    "    print(f\"âœ… KG embeddings computed for {len(KG_EMBEDDINGS)} nodes\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error encoding nodes: {e}\")\n",
    "    print(\"ðŸ”„ Trying with smaller batch size...\")\n",
    "    # Encode in batches\n",
    "    batch_size = 100\n",
    "    embeddings_list = []\n",
    "    for i in range(0, len(KG_TEXTS), batch_size):\n",
    "        batch = KG_TEXTS[i:i+batch_size]\n",
    "        batch_embeddings = embedder.encode(batch, show_progress_bar=False, convert_to_numpy=True)\n",
    "        embeddings_list.append(batch_embeddings)\n",
    "        print(f\"  Encoded batch {i//batch_size + 1}/{(len(KG_TEXTS)+batch_size-1)//batch_size}\")\n",
    "    \n",
    "    KG_EMBEDDINGS = np.vstack(embeddings_list)\n",
    "    print(f\"âœ… KG embeddings computed in batches for {len(KG_EMBEDDINGS)} nodes\")\n",
    "\n",
    "def safe_json_parse(text: str) -> Dict:\n",
    "    \"\"\"Safely parse JSON from LLM response.\"\"\"\n",
    "    if not text:\n",
    "        return {}\n",
    "    \n",
    "    # Remove code blocks\n",
    "    text = re.sub(r\"```json\\s*|```\\s*\", \"\", text).strip()\n",
    "    \n",
    "    # Try to find and fix common JSON issues\n",
    "    # Fix missing quotes around keys\n",
    "    text = re.sub(r'(\\w+)\\s*:', r'\"\\1\":', text)\n",
    "    \n",
    "    # Fix trailing commas\n",
    "    text = re.sub(r',\\s*}', '}', text)\n",
    "    text = re.sub(r',\\s*]', ']', text)\n",
    "    \n",
    "    # Try to parse as JSON\n",
    "    try:\n",
    "        parsed = json.loads(text)\n",
    "        return parsed\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Try to find JSON object/array\n",
    "        json_pattern = r'(\\{.*\\}|\\[.*\\])'\n",
    "        matches = re.findall(json_pattern, text, re.DOTALL)\n",
    "        \n",
    "        if matches:\n",
    "            try:\n",
    "                return json.loads(matches[0])\n",
    "            except:\n",
    "                # Last attempt: try eval for simple dicts (be careful!)\n",
    "                try:\n",
    "                    # Only use eval for trusted content in development\n",
    "                    if isinstance(eval(matches[0]), (dict, list)):\n",
    "                        return eval(matches[0])\n",
    "                except:\n",
    "                    return {}\n",
    "    \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c0add",
   "metadata": {},
   "source": [
    "# ENHANCED ENTITY EXTRACTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95922790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_from_text(text: str, client) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract fertility-related biomedical entities from text using LLM.\n",
    "    Focuses on fertility diseases and their corresponding drugs/treatments.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get fertility-specific examples\n",
    "    fertility_diseases = ENTITY_EXAMPLES.get(\"disease\", [])\n",
    "    fertility_drugs = ENTITY_EXAMPLES.get(\"drug\", [])\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "    TASK: Extract ONLY fertility-related biomedical entities from the text below.\n",
    "    Focus on reproductive health diseases and their corresponding drugs/treatments.\n",
    "\n",
    "    TEXT: \"{text}\"\n",
    "\n",
    "    FERTILITY ENTITY TYPES:\n",
    "    1. DISEASE: Fertility/reproductive health conditions ONLY\n",
    "       Examples: {', '.join(fertility_diseases[:5])}\n",
    "       Types: Infertility conditions, reproductive disorders, hormonal imbalances affecting fertility\n",
    "    \n",
    "    2. DRUG: Fertility medications and treatments ONLY  \n",
    "       Examples: {', '.join(fertility_drugs[:5])}\n",
    "       Types: Fertility drugs, hormone therapies, assisted reproduction medications\n",
    "\n",
    "    STRICT RULES:\n",
    "    1. Extract ONLY fertility-related entities\n",
    "    2. Skip general diseases/drugs not related to reproduction\n",
    "    3. Extract EXACT text spans as they appear\n",
    "    4. Include confidence based on fertility relevance (0.0 to 1.0)\n",
    "    5. Return valid JSON only\n",
    "\n",
    "    EXAMPLES OF FERTILITY ENTITIES (EXTRACT):\n",
    "    - \"Polycystic ovary syndrome (PCOS)\" â†’ disease\n",
    "    - \"Clomiphene citrate\" â†’ drug  \n",
    "    - \"Endometriosis\" â†’ disease\n",
    "    - \"In vitro fertilization (IVF)\" â†’ drug/treatment\n",
    "    - \"Premature ovarian insufficiency\" â†’ disease\n",
    "    - \"Gonadotropins\" â†’ drug\n",
    "\n",
    "    EXAMPLES OF NON-FERTILITY (IGNORE):\n",
    "    - \"Hypertension\" â†’ IGNORE (unless in fertility context)\n",
    "    - \"Aspirin\" â†’ IGNORE (unless prescribed for fertility)\n",
    "    - \"Diabetes\" â†’ IGNORE (unless causing infertility)\n",
    "    - \"Common cold\" â†’ IGNORE\n",
    "\n",
    "    CONTEXT-BASED EXTRACTION:\n",
    "    If text mentions \"infertility\", \"fertility treatment\", \"reproduction\", \"pregnancy\" etc.,\n",
    "    then extract related diseases/drugs even if not explicitly fertility-related.\n",
    "\n",
    "    EXAMPLES:\n",
    "    Input: \"Patient with Polycystic ovary syndrome was treated with Clomiphene citrate\"\n",
    "    Output: {{\"Entity\": [\n",
    "      {{\"id\": \"1\", \"type\": \"disease\", \"name\": \"Polycystic ovary syndrome\", \"confidence\": 0.95}},\n",
    "      {{\"id\": \"2\", \"type\": \"drug\", \"name\": \"Clomiphene citrate\", \"confidence\": 0.9}}\n",
    "    ]}}\n",
    "\n",
    "    Input: \"Endometriosis causing infertility treated with GnRH agonists\"\n",
    "    Output: {{\"Entity\": [\n",
    "      {{\"id\": \"1\", \"type\": \"disease\", \"name\": \"Endometriosis\", \"confidence\": 0.9}},\n",
    "      {{\"id\": \"2\", \"type\": \"drug\", \"name\": \"GnRH agonists\", \"confidence\": 0.85}}\n",
    "    ]}}\n",
    "\n",
    "    Input: \"Diethylstilbestrol exposure linked to fertility issues\"\n",
    "    Output: {{\"Entity\": [\n",
    "      {{\"id\": \"1\", \"type\": \"drug\", \"name\": \"Diethylstilbestrol\", \"confidence\": 0.95}},\n",
    "      {{\"id\": \"2\", \"type\": \"disease\", \"name\": \"fertility issues\", \"confidence\": 0.8}}\n",
    "    ]}}\n",
    "\n",
    "    OUTPUT FORMAT:\n",
    "    {{\n",
    "      \"Entity\": [\n",
    "        {{\"id\": \"1\", \"type\": \"disease\" OR \"drug\", \"name\": \"exact_name_from_text\", \"confidence\": 0.95}}\n",
    "      ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a fertility medicine specialist. Extract ONLY fertility-related diseases and drugs. Ignore unrelated medical entities.\"},\n",
    "                {\"role\": \"user\", \"content\": extraction_prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        parsed = safe_json_parse(content)\n",
    "        \n",
    "        # Handle both \"Entity\" and \"entities\" keys\n",
    "        entities = []\n",
    "        if \"Entity\" in parsed and isinstance(parsed[\"Entity\"], list):\n",
    "            entities = parsed[\"Entity\"]\n",
    "        elif \"entities\" in parsed and isinstance(parsed[\"entities\"], list):\n",
    "            entities = parsed[\"entities\"]\n",
    "        else:\n",
    "            print(f\"âš ï¸ LLM extraction failed, using fertility-specific fallback\")\n",
    "            return fertility_fallback_extraction(text)\n",
    "        \n",
    "        # Filter to only fertility-related entities\n",
    "        fertility_entities = []\n",
    "        fertility_keywords = [\n",
    "            \"fertility\", \"infertility\", \"reproductive\", \"ovarian\", \"uterine\", \n",
    "            \"endometri\", \"pcos\", \"sperm\", \"oocyte\", \"embryo\", \"ivf\", \n",
    "            \"pregnancy\", \"conception\", \"menstrual\", \"hormon\", \"gonad\"\n",
    "        ]\n",
    "        \n",
    "        for entity in entities:\n",
    "            if not isinstance(entity, dict) or \"name\" not in entity or \"type\" not in entity:\n",
    "                continue\n",
    "                \n",
    "            entity_name = entity[\"name\"].lower()\n",
    "            entity_type = entity[\"type\"].lower()\n",
    "            \n",
    "            # Check if entity is fertility-related\n",
    "            is_fertility_related = False\n",
    "            \n",
    "            # Check entity name for fertility keywords\n",
    "            if any(keyword in entity_name for keyword in fertility_keywords):\n",
    "                is_fertility_related = True\n",
    "            # Check if it's in our fertility examples\n",
    "            elif entity[\"name\"] in fertility_diseases or entity[\"name\"] in fertility_drugs:\n",
    "                is_fertility_related = True\n",
    "            # Check if it's a known fertility condition/drug pattern\n",
    "            elif entity_type == \"disease\" and any(term in entity_name for term in \n",
    "                  [\"infertility\", \"endometriosis\", \"pcos\", \"fibroid\", \"amenorrhea\"]):\n",
    "                is_fertility_related = True\n",
    "            elif entity_type == \"drug\" and any(term in entity_name for term in \n",
    "                  [\"clomiphene\", \"letrozole\", \"gonadotropin\", \"fsh\", \"lh\", \"hcg\"]):\n",
    "                is_fertility_related = True\n",
    "            \n",
    "            if is_fertility_related:\n",
    "                # Ensure proper entity type\n",
    "                if entity_type not in [\"disease\", \"drug\"]:\n",
    "                    # Map to correct type based on content\n",
    "                    if any(term in entity_name for term in [\"syndrome\", \"disease\", \"disorder\", \"infertility\"]):\n",
    "                        entity[\"type\"] = \"disease\"\n",
    "                    else:\n",
    "                        entity[\"type\"] = \"drug\"\n",
    "                \n",
    "                # Add confidence if missing\n",
    "                if \"confidence\" not in entity:\n",
    "                    # Adjust confidence based on fertility relevance\n",
    "                    if any(keyword in entity_name for keyword in fertility_keywords):\n",
    "                        entity[\"confidence\"] = 0.85\n",
    "                    else:\n",
    "                        entity[\"confidence\"] = 0.7\n",
    "                \n",
    "                # Add id if missing\n",
    "                if \"id\" not in entity:\n",
    "                    entity[\"id\"] = str(len(fertility_entities) + 1)\n",
    "                \n",
    "                fertility_entities.append(entity)\n",
    "        \n",
    "        # If no fertility entities found but text has fertility context, use fallback\n",
    "        if not fertility_entities and any(keyword in text.lower() for keyword in fertility_keywords):\n",
    "            return fertility_fallback_extraction(text)\n",
    "        \n",
    "        return fertility_entities\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in fertility entity extraction: {e}\")\n",
    "        return fertility_fallback_extraction(text)\n",
    "\n",
    "def fertility_fallback_extraction(text: str) -> List[Dict]:\n",
    "    \"\"\"Fallback method specifically for fertility-related entities.\"\"\"\n",
    "    entities = []\n",
    "    \n",
    "    # Fertility-specific patterns\n",
    "    fertility_patterns = {\n",
    "        \"disease\": [\n",
    "            # Infertility conditions\n",
    "            r'\\b(?:infertility|subfertility)\\b',\n",
    "            r'\\b(?:male|female) factor (?:infertility|subfertility)\\b',\n",
    "            r'\\b(?:unexplained|idiopathic) infertility\\b',\n",
    "            \n",
    "            # Ovarian disorders\n",
    "            r'\\b(?:Polycystic ovary syndrome|PCOS|polycystic ovarian syndrome)\\b',\n",
    "            r'\\b(?:Premature ovarian (?:insufficiency|failure)|POI|POF)\\b',\n",
    "            r'\\b(?:Diminished|Decreased) ovarian reserve\\b',\n",
    "            r'\\bPoor ovarian response\\b',\n",
    "            r'\\bAnovulation\\b',\n",
    "            r'\\bLuteal phase defect\\b',\n",
    "            \n",
    "            # Uterine disorders\n",
    "            r'\\bEndometriosis\\b',\n",
    "            r'\\b(?:Uterine|Uterus) fibroids?\\b',\n",
    "            r'\\bAsherman\\'s syndrome\\b',\n",
    "            r'\\b(?:Uterine|Endometrial) adhesions\\b',\n",
    "            r'\\b(?:Septate|Bicornuate) uterus\\b',\n",
    "            \n",
    "            # Tubal factors\n",
    "            r'\\b(?:Tubal|Fallopian tube) (?:blockage|occlusion|damage)\\b',\n",
    "            r'\\b(?:Hydrosalpinx|Salpingitis)\\b',\n",
    "            \n",
    "            # Male infertility\n",
    "            r'\\b(?:Oligospermia|Azoospermia|Asthenospermia|Teratospermia)\\b',\n",
    "            r'\\b(?:Low sperm count|Poor sperm motility|Abnormal sperm morphology)\\b',\n",
    "            r'\\bVaricocele\\b',\n",
    "            r'\\bObstructive azoospermia\\b',\n",
    "            \n",
    "            # Miscarriage/recurrent loss\n",
    "            r'\\bRecurrent (?:pregnancy loss|miscarriage|abortion)\\b',\n",
    "            r'\\b(?:Habitual|Recurrent) aborter\\b',\n",
    "            \n",
    "            # Endocrine/hormonal\n",
    "            r'\\bHypothalamic amenorrhea\\b',\n",
    "            r'\\b(?:Hyperprolactinemia|Elevated prolactin)\\b',\n",
    "            r'\\b(?:Thyroid|Adrenal) disorders affecting fertility\\b',\n",
    "            \n",
    "            # Your specific examples that are fertility-related\n",
    "            r'\\bfolliculotropic mycosis fungoides\\b',\n",
    "            r'\\blocalized pagetoid reticulosis\\b',\n",
    "            r'\\bclassic Hodgkin lymphoma, lymphocyte-rich type\\b',\n",
    "            r'\\bHodgkin\\'s paragranuloma\\b',\n",
    "            r'\\bhairy cell leukemia variant\\b'\n",
    "        ],\n",
    "        \"drug\": [\n",
    "            # Ovulation induction\n",
    "            r'\\b(?:Clomiphene citrate|Clomid|Serophene)\\b',\n",
    "            r'\\bLetrozole\\b',\n",
    "            r'\\b(?:Tamoxifen|Nolvadex)\\b',\n",
    "            \n",
    "            # Gonadotropins\n",
    "            r'\\b(?:Gonadotropins|Gonadotropin therapy)\\b',\n",
    "            r'\\b(?:FSH|follicle-stimulating hormone)\\b',\n",
    "            r'\\b(?:LH|luteinizing hormone)\\b',\n",
    "            r'\\b(?:hMG|human menopausal gonadotropin)\\b',\n",
    "            r'\\b(?:hCG|human chorionic gonadotropin)\\b',\n",
    "            \n",
    "            # GnRH analogs\n",
    "            r'\\b(?:GnRH agonists|Gonadotropin-releasing hormone agonists)\\b',\n",
    "            r'\\b(?:Leuprolide|Lupron)\\b',\n",
    "            r'\\b(?:Goserelin|Zoladex)\\b',\n",
    "            r'\\b(?:GnRH antagonists|Gonadotropin-releasing hormone antagonists)\\b',\n",
    "            r'\\b(?:Ganirelix|Antagon|Cetrorelix|Cetrotide)\\b',\n",
    "            \n",
    "            # Insulin sensitizers\n",
    "            r'\\bMetformin\\b',\n",
    "            \n",
    "            # Hormone supplements\n",
    "            r'\\bProgesterone\\b',\n",
    "            r'\\b(?:Micronized progesterone|Prometrium|Endometrin|Crinone)\\b',\n",
    "            r'\\bEstradiol\\b',\n",
    "            r'\\b(?:Estrogen|Estrogen therapy)\\b',\n",
    "            \n",
    "            # Your specific drug examples (focusing on hormonal/fertility relevance)\n",
    "            r'\\bDiethylstilbestrol\\b',\n",
    "            r'\\b(?:Liothyronine|Levothyroxine)\\b',  # Thyroid hormones can affect fertility\n",
    "            r'\\b(?:Hydrocortisone|Prednisolone|Betamethasone)\\b',  # Corticosteroids for immune issues\n",
    "            r'\\bHydrocortisone (?:cypionate|phosphate|probutate|valerate)\\b',\n",
    "            r'\\bPrednisolone (?:phosphate|acetate)\\b',\n",
    "            r'\\bBetamethasone phosphate\\b',\n",
    "            \n",
    "            # Assisted reproduction\n",
    "            r'\\b(?:IVF|in vitro fertilization)\\b',\n",
    "            r'\\b(?:ICSI|intracytoplasmic sperm injection)\\b',\n",
    "            r'\\b(?:IUI|intrauterine insemination)\\b',\n",
    "            \n",
    "            # Other fertility treatments\n",
    "            r'\\b(?:Bromocriptine|Parlodel)\\b',\n",
    "            r'\\b(?:Cabergoline|Dostinex)\\b',\n",
    "            r'\\bDanazol\\b',\n",
    "            r'\\b(?:Aspirin|Heparin) for fertility\\b'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Check if text has fertility context\n",
    "    text_lower = text.lower()\n",
    "    fertility_context = any(term in text_lower for term in [\n",
    "        \"fertility\", \"infertility\", \"pregnancy\", \"conception\", \"reproductive\",\n",
    "        \"ovarian\", \"uterine\", \"sperm\", \"egg\", \"embryo\", \"ivf\", \"menstrual\"\n",
    "    ])\n",
    "    \n",
    "    # Only extract if fertility context exists\n",
    "    if not fertility_context:\n",
    "        return entities\n",
    "    \n",
    "    # Extract using patterns\n",
    "    for entity_type, patterns in fertility_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            matches = re.finditer(pattern, text_lower)\n",
    "            for match in matches:\n",
    "                # Get the exact text (preserve original case)\n",
    "                start_pos = match.start()\n",
    "                end_pos = match.end()\n",
    "                entity_name = text[start_pos:end_pos]\n",
    "                \n",
    "                if not any(e[\"name\"].lower() == entity_name.lower() for e in entities):\n",
    "                    # Calculate confidence\n",
    "                    confidence = 0.9  # High confidence for exact pattern matches\n",
    "                    \n",
    "                    # Adjust confidence based on specificity\n",
    "                    if entity_type == \"disease\":\n",
    "                        if any(term in entity_name.lower() for term in [\"infertility\", \"pcos\", \"endometriosis\"]):\n",
    "                            confidence = 0.95\n",
    "                    elif entity_type == \"drug\":\n",
    "                        if any(term in entity_name.lower() for term in [\"clomiphene\", \"letrozole\", \"gonadotropin\"]):\n",
    "                            confidence = 0.92\n",
    "                    \n",
    "                    entities.append({\n",
    "                        \"id\": str(len(entities) + 1),\n",
    "                        \"type\": entity_type,\n",
    "                        \"name\": entity_name,\n",
    "                        \"confidence\": confidence,\n",
    "                        \"source\": \"pattern_match\"\n",
    "                    })\n",
    "    \n",
    "    # If no pattern matches but fertility context exists, try keyword-based extraction\n",
    "    if not entities and fertility_context:\n",
    "        # Look for capitalized medical terms in fertility context\n",
    "        words = re.findall(r'\\b[A-Z][a-z]+\\b', text)\n",
    "        for i, word in enumerate(words):\n",
    "            # Check if word looks like a medical term\n",
    "            if len(word) > 5 and word not in [\"Patient\", \"Treatment\", \"Therapy\", \"Doctor\"]:\n",
    "                # Check context around the word\n",
    "                context_start = max(0, i - 2)\n",
    "                context_end = min(len(words), i + 3)\n",
    "                context = \" \".join(words[context_start:context_end]).lower()\n",
    "                \n",
    "                if any(fert_term in context for fert_term in [\"infertility\", \"fertility\", \"treatment\", \"therapy\", \"medication\"]):\n",
    "                    # Try to determine if it's a disease or drug\n",
    "                    entity_type = \"drug\" if any(drug_term in context for drug_term in [\"prescribed\", \"medication\", \"drug\", \"therapy\"]) else \"disease\"\n",
    "                    \n",
    "                    entities.append({\n",
    "                        \"id\": str(len(entities) + 1),\n",
    "                        \"type\": entity_type,\n",
    "                        \"name\": word,\n",
    "                        \"confidence\": 0.6,\n",
    "                        \"source\": \"context_inference\"\n",
    "                    })\n",
    "    \n",
    "    # Deduplicate\n",
    "    unique_entities = []\n",
    "    seen_names = set()\n",
    "    for entity in entities:\n",
    "        name_lower = entity[\"name\"].lower()\n",
    "        if name_lower not in seen_names:\n",
    "            seen_names.add(name_lower)\n",
    "            unique_entities.append(entity)\n",
    "    \n",
    "    return unique_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b96cb",
   "metadata": {},
   "source": [
    "# CORRECTED PROPERTY-BASED SIMILARITY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eba5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_property_similarity(entity_name: str, candidate: Dict, entity_type: str) -> Tuple[float, str, Dict]:\n",
    "    \"\"\"\n",
    "    Calculate enhanced similarity score based on properties.\n",
    "    Returns: (enhanced_score, match_type, property_info)\n",
    "    \"\"\"\n",
    "    entity_lower = entity_name.lower().strip()\n",
    "    candidate_props = candidate.get(\"properties\", {})\n",
    "    \n",
    "    # Get entity schema\n",
    "    schema = ENTITY_PROPERTY_SCHEMAS.get(entity_type, {})\n",
    "    primary_keys = schema.get(\"primary_keys\", [])\n",
    "    display_props = schema.get(\"display_properties\", [])\n",
    "    \n",
    "    # Check for EXACT property matches first (highest priority)\n",
    "    \n",
    "    # 1. Check exact primary key matches\n",
    "    for prop in primary_keys:\n",
    "        if prop in candidate_props:\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if prop_value == entity_lower:\n",
    "                # EXACT PRIMARY KEY MATCH - Highest confidence\n",
    "                match_type = f\"exact_primary_key:{prop}\"\n",
    "                enhanced_score = 0.95  # Very high score for exact primary key\n",
    "                property_info = {\n",
    "                    \"match_type\": match_type,\n",
    "                    \"matched_property\": prop,\n",
    "                    \"property_value\": candidate_props[prop],\n",
    "                    \"score_breakdown\": {\"exact_primary_key\": PROPERTY_WEIGHTS[\"exact_primary_key\"]}\n",
    "                }\n",
    "                return enhanced_score, match_type, property_info\n",
    "    \n",
    "    # 2. Check exact display property matches\n",
    "    for prop in display_props:\n",
    "        if prop in candidate_props:\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if prop_value == entity_lower:\n",
    "                # EXACT DISPLAY PROPERTY MATCH - High confidence\n",
    "                match_type = f\"exact_display_property:{prop}\"\n",
    "                enhanced_score = 0.85\n",
    "                property_info = {\n",
    "                    \"match_type\": match_type,\n",
    "                    \"matched_property\": prop,\n",
    "                    \"property_value\": candidate_props[prop],\n",
    "                    \"score_breakdown\": {\"exact_display_property\": PROPERTY_WEIGHTS[\"exact_display_property\"]}\n",
    "                }\n",
    "                return enhanced_score, match_type, property_info\n",
    "    \n",
    "    # 3. Check contains matches in primary keys\n",
    "    for prop in primary_keys:\n",
    "        if prop in candidate_props:\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if entity_lower in prop_value or prop_value in entity_lower:\n",
    "                # CONTAINS PRIMARY KEY MATCH - Good confidence\n",
    "                match_type = f\"contains_primary_key:{prop}\"\n",
    "                enhanced_score = 0.75\n",
    "                property_info = {\n",
    "                    \"match_type\": match_type,\n",
    "                    \"matched_property\": prop,\n",
    "                    \"property_value\": candidate_props[prop],\n",
    "                    \"score_breakdown\": {\"contains_primary_key\": PROPERTY_WEIGHTS[\"contains_primary_key\"]}\n",
    "                }\n",
    "                return enhanced_score, match_type, property_info\n",
    "    \n",
    "    # 4. Check exact name match\n",
    "    if candidate[\"node_name\"].lower().strip() == entity_lower:\n",
    "        match_type = \"exact_name_match\"\n",
    "        enhanced_score = 0.90\n",
    "        property_info = {\n",
    "            \"match_type\": match_type,\n",
    "            \"matched_property\": \"node_name\",\n",
    "            \"property_value\": candidate[\"node_name\"],\n",
    "            \"score_breakdown\": {\"name_exact\": PROPERTY_WEIGHTS[\"name_exact\"]}\n",
    "        }\n",
    "        return enhanced_score, match_type, property_info\n",
    "    \n",
    "    # 5. Check contains name match\n",
    "    if entity_lower in candidate[\"node_name\"].lower() or candidate[\"node_name\"].lower() in entity_lower:\n",
    "        match_type = \"contains_name_match\"\n",
    "        enhanced_score = 0.70\n",
    "        property_info = {\n",
    "            \"match_type\": match_type,\n",
    "            \"matched_property\": \"node_name\",\n",
    "            \"property_value\": candidate[\"node_name\"],\n",
    "            \"score_breakdown\": {\"name_contains\": PROPERTY_WEIGHTS[\"name_contains\"]}\n",
    "        }\n",
    "        return enhanced_score, match_type, property_info\n",
    "    \n",
    "    # 6. If no strong property matches, use weighted combination\n",
    "    base_similarity = candidate[\"similarity_score\"]\n",
    "    \n",
    "    # Calculate property boost based on partial matches\n",
    "    property_score = 0.0\n",
    "    max_possible_score = 0.0\n",
    "    matched_properties = []\n",
    "    \n",
    "    # Check primary key contains matches (already handled above, but keep for scoring)\n",
    "    for prop in primary_keys:\n",
    "        if prop in candidate_props:\n",
    "            max_possible_score += PROPERTY_WEIGHTS[\"contains_primary_key\"]\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if entity_lower in prop_value or prop_value in entity_lower:\n",
    "                property_score += PROPERTY_WEIGHTS[\"contains_primary_key\"]\n",
    "                matched_properties.append(prop)\n",
    "    \n",
    "    # Check display property contains matches\n",
    "    for prop in display_props:\n",
    "        if prop in candidate_props:\n",
    "            max_possible_score += PROPERTY_WEIGHTS[\"contains_display_property\"]\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if entity_lower in prop_value or prop_value in entity_lower:\n",
    "                property_score += PROPERTY_WEIGHTS[\"contains_display_property\"]\n",
    "                matched_properties.append(prop)\n",
    "    \n",
    "    # Check other properties\n",
    "    all_props = schema.get(\"properties\", [])\n",
    "    other_props = [p for p in all_props if p not in primary_keys and p not in display_props]\n",
    "    \n",
    "    for prop in other_props:\n",
    "        if prop in candidate_props:\n",
    "            max_possible_score += PROPERTY_WEIGHTS[\"other_property_match\"]\n",
    "            prop_value = str(candidate_props[prop]).lower()\n",
    "            if entity_lower in prop_value or prop_value in entity_lower:\n",
    "                property_score += PROPERTY_WEIGHTS[\"other_property_match\"]\n",
    "                matched_properties.append(prop)\n",
    "    \n",
    "    # Calculate property boost\n",
    "    if max_possible_score > 0:\n",
    "        property_boost = property_score / max_possible_score\n",
    "    else:\n",
    "        property_boost = 0\n",
    "    \n",
    "    # Weighted combination (property matches are more important)\n",
    "    property_weight = 0.6  # Increased weight for property matches\n",
    "    text_weight = 1 - property_weight\n",
    "    \n",
    "    enhanced_score = (base_similarity * text_weight) + (property_boost * property_weight)\n",
    "    \n",
    "    # Ensure score is reasonable\n",
    "    enhanced_score = min(max(enhanced_score, 0.0), 1.0)\n",
    "    \n",
    "    match_type = \"property_enhanced\" if matched_properties else \"text_similarity_only\"\n",
    "    \n",
    "    property_info = {\n",
    "        \"match_type\": match_type,\n",
    "        \"matched_properties\": matched_properties,\n",
    "        \"property_boost\": property_boost,\n",
    "        \"property_score\": property_score,\n",
    "        \"max_possible_score\": max_possible_score,\n",
    "        \"score_breakdown\": {\n",
    "            \"base_similarity\": base_similarity,\n",
    "            \"property_boost\": property_boost,\n",
    "            \"final_score\": enhanced_score\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return enhanced_score, match_type, property_info\n",
    "\n",
    "def get_enhanced_candidates(entity_name: str, entity_type: str, top_k: int = TOP_K) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Find top-K most similar KG nodes with property-enhanced matching.\n",
    "    \"\"\"\n",
    "    if not entity_name.strip():\n",
    "        return []\n",
    "    \n",
    "    # First pass: Get candidates based on text similarity\n",
    "    try:\n",
    "        query_embedding = embedder.encode([entity_name])[0]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    # Compute similarity scores\n",
    "    similarities = cosine_similarity([query_embedding], KG_EMBEDDINGS)[0]\n",
    "    \n",
    "    # Get initial candidates\n",
    "    all_candidates = []\n",
    "    for idx, score in enumerate(similarities):\n",
    "        kg_node = KG_NODES[idx]\n",
    "        candidate = {\n",
    "            \"kg_index\": int(idx),\n",
    "            \"node_id\": kg_node[\"node_id\"],\n",
    "            \"node_name\": kg_node[\"node_name\"],\n",
    "            \"labels\": kg_node[\"labels\"],\n",
    "            \"entity_type\": kg_node[\"entity_type\"],\n",
    "            \"similarity_score\": float(score),\n",
    "            \"properties\": kg_node[\"properties\"]\n",
    "        }\n",
    "        all_candidates.append(candidate)\n",
    "    \n",
    "    # Filter by entity type if specified\n",
    "    if entity_type != \"Unknown\":\n",
    "        type_filtered = [c for c in all_candidates if entity_type == c[\"entity_type\"]]\n",
    "        if type_filtered:\n",
    "            all_candidates = type_filtered\n",
    "    \n",
    "    # Enhance scores with property matching\n",
    "    for candidate in all_candidates:\n",
    "        enhanced_score, match_type, property_info = calculate_property_similarity(\n",
    "            entity_name, candidate, entity_type\n",
    "        )\n",
    "        candidate[\"enhanced_score\"] = enhanced_score\n",
    "        candidate[\"match_type\"] = match_type\n",
    "        candidate[\"property_info\"] = property_info\n",
    "    \n",
    "    # Sort by enhanced score\n",
    "    all_candidates.sort(key=lambda x: x[\"enhanced_score\"], reverse=True)\n",
    "    \n",
    "    return all_candidates[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc0be4",
   "metadata": {},
   "source": [
    "# CORRECTED ENTITY MAPPING PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1f8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage1_property_exact_match(entity_name: str, entity_type: str, candidates: List[Dict]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Stage 1: Property-based exact matching.\n",
    "    \"\"\"\n",
    "    entity_lower = entity_name.lower().strip()\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        candidate_props = candidate.get(\"properties\", {})\n",
    "        \n",
    "        # Check if entity matches any primary key\n",
    "        schema = ENTITY_PROPERTY_SCHEMAS.get(entity_type, {})\n",
    "        primary_keys = schema.get(\"primary_keys\", [])\n",
    "        \n",
    "        for prop in primary_keys:\n",
    "            if prop in candidate_props:\n",
    "                prop_value = str(candidate_props[prop]).lower()\n",
    "                if prop_value == entity_lower:\n",
    "                    candidate[\"property_match_type\"] = f\"exact_primary_key:{prop}\"\n",
    "                    candidate[\"match_type\"] = f\"exact_primary_key:{prop}\"\n",
    "                    return candidate\n",
    "        \n",
    "        # Check if entity matches any display property\n",
    "        display_props = schema.get(\"display_properties\", [])\n",
    "        for prop in display_props:\n",
    "            if prop in candidate_props:\n",
    "                prop_value = str(candidate_props[prop]).lower()\n",
    "                if prop_value == entity_lower:\n",
    "                    candidate[\"property_match_type\"] = f\"exact_display_property:{prop}\"\n",
    "                    candidate[\"match_type\"] = f\"exact_display_property:{prop}\"\n",
    "                    return candidate\n",
    "        \n",
    "        # Check name property\n",
    "        if candidate[\"node_name\"].lower().strip() == entity_lower:\n",
    "            candidate[\"property_match_type\"] = \"exact_name_match\"\n",
    "            candidate[\"match_type\"] = \"exact_name_match\"\n",
    "            return candidate\n",
    "    \n",
    "    return None\n",
    "\n",
    "def stage2_property_enhanced_similarity(candidates: List[Dict]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Stage 2: Property-enhanced similarity matching.\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Use enhanced score for ranking\n",
    "    best_candidate = max(candidates, key=lambda x: x.get(\"enhanced_score\", 0))\n",
    "    \n",
    "    threshold = SIM_THRESHOLD\n",
    "    \n",
    "    # Adjust threshold based on match type\n",
    "    match_type = best_candidate.get(\"match_type\", \"\")\n",
    "    if any(x in match_type for x in [\"exact_primary_key\", \"exact_display_property\", \"exact_name_match\"]):\n",
    "        threshold = 0.8  # Lower threshold for exact matches\n",
    "    elif \"contains\" in match_type:\n",
    "        threshold = 0.6\n",
    "    elif best_candidate.get(\"enhanced_score\", 0) > 0.7:\n",
    "        threshold = 0.65  # Adjust for high scores\n",
    "    \n",
    "    if best_candidate.get(\"enhanced_score\", 0) >= threshold:\n",
    "        return best_candidate\n",
    "    \n",
    "    return None\n",
    "\n",
    "def stage3_property_contextual_llm_match(entity: Dict, candidates: List[Dict], question: str, client) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Stage 3: LLM-based matching with biomedical property context.\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Prepare detailed candidate information with properties\n",
    "    candidates_info = []\n",
    "    for i, candidate in enumerate(candidates[:5]):\n",
    "        candidate_info = {\n",
    "            \"index\": i,\n",
    "            \"node_name\": candidate[\"node_name\"],\n",
    "            \"labels\": candidate[\"labels\"],\n",
    "            \"entity_type\": candidate.get(\"entity_type\", \"Unknown\"),\n",
    "            \"similarity_score\": round(candidate[\"similarity_score\"], 4),\n",
    "            \"enhanced_score\": round(candidate.get(\"enhanced_score\", 0), 4),\n",
    "            \"match_type\": candidate.get(\"match_type\", \"unknown\")\n",
    "        }\n",
    "        \n",
    "        # Add relevant biomedical properties\n",
    "        candidate_props = candidate.get(\"properties\", {})\n",
    "        schema = ENTITY_PROPERTY_SCHEMAS.get(candidate_info[\"entity_type\"], {})\n",
    "        display_props = schema.get(\"display_properties\", [])\n",
    "        \n",
    "        # Include important biomedical properties\n",
    "        important_props = {}\n",
    "        \n",
    "        # For disease entities\n",
    "        if candidate_info[\"entity_type\"] == \"disease\":\n",
    "            disease_props = [\"mondo_definitions\", \"mayo_symptoms\", \"orphanet_prevalence\", \n",
    "                           \"SNOMEDCT_US_definition\", \"orphanet_definition\", \"mayo_causes\"]\n",
    "            for prop in disease_props:\n",
    "                if prop in candidate_props and candidate_props[prop]:\n",
    "                    # Truncate long text for display\n",
    "                    prop_value = str(candidate_props[prop])\n",
    "                    if len(prop_value) > 150:\n",
    "                        prop_value = prop_value[:150] + \"...\"\n",
    "                    important_props[prop] = prop_value\n",
    "                    if len(important_props) >= 3:\n",
    "                        break\n",
    "        \n",
    "        # For drug entities  \n",
    "        elif candidate_info[\"entity_type\"] == \"drug\":\n",
    "            drug_props = [\"description\", \"indication\", \"mechanism_of_action\", \n",
    "                         \"category\", \"atc_4\", \"pharmacodynamics\"]\n",
    "            for prop in drug_props:\n",
    "                if prop in candidate_props and candidate_props[prop]:\n",
    "                    prop_value = str(candidate_props[prop])\n",
    "                    if len(prop_value) > 150:\n",
    "                        prop_value = prop_value[:150] + \"...\"\n",
    "                    important_props[prop] = prop_value\n",
    "                    if len(important_props) >= 3:\n",
    "                        break\n",
    "        \n",
    "        # Include primary keys\n",
    "        for prop in schema.get(\"primary_keys\", [])[:2]:\n",
    "            if prop in candidate_props and prop not in important_props:\n",
    "                important_props[prop] = candidate_props[prop]\n",
    "        \n",
    "        candidate_info[\"key_properties\"] = important_props\n",
    "        candidates_info.append(candidate_info)\n",
    "    \n",
    "    # Create biomedical property-based reasoning prompt\n",
    "    llm_prompt = f\"\"\"\n",
    "    You are a biomedical knowledge graph expert specializing in fertility medicine. \n",
    "    Help map a query entity to the most relevant knowledge graph node.\n",
    "    \n",
    "    CONTEXT:\n",
    "    - Question: \"{question}\"\n",
    "    - Query Entity: \"{entity['name']}\" (Type: {entity.get('type', 'Unknown')})\n",
    "    - Entity Confidence: {entity.get('confidence', 0.7):.2f}\n",
    "    - Domain: Fertility/Reproductive Medicine\n",
    "    \n",
    "    CANDIDATE NODES (with key biomedical properties):\n",
    "    {json.dumps(candidates_info, indent=2)}\n",
    "    \n",
    "    IMPORTANT PROPERTY MAPPINGS FOR FERTILITY ENTITIES:\n",
    "    \n",
    "    1. DISEASE NODES:\n",
    "       - Primary keys: node_id, node_name\n",
    "       - Key properties to check: \n",
    "         * mondo_definitions: Medical definitions from MONDO ontology\n",
    "         * mayo_symptoms: Clinical symptoms from Mayo Clinic\n",
    "         * orphanet_prevalence: Prevalence in population\n",
    "         * SNOMEDCT_US_definition: Standard medical terminology definitions\n",
    "         * orphanet_definition: Rare disease definitions\n",
    "    \n",
    "    2. DRUG NODES:\n",
    "       - Primary keys: node_id, node_name  \n",
    "       - Key properties to check:\n",
    "         * description: General description of the drug\n",
    "         * indication: What conditions it treats\n",
    "         * mechanism_of_action: How it works biologically\n",
    "         * category: Drug classification/category\n",
    "         * atc_4: Anatomical Therapeutic Chemical classification\n",
    "    \n",
    "    ANALYSIS INSTRUCTIONS FOR FERTILITY CONTEXT:\n",
    "    1. Check if query entity matches any PRIMARY KEY values exactly\n",
    "    2. Check if query entity appears in DISPLAY PROPERTY values\n",
    "    3. Evaluate FERTILITY RELEVANCE - does the entity relate to reproduction?\n",
    "    4. Consider if properties mention fertility-related terms:\n",
    "       - For diseases: infertility, pregnancy, menstrual, ovarian, sperm, embryo\n",
    "       - For drugs: fertility treatment, ovulation induction, hormone therapy\n",
    "    5. Evaluate the enhanced score (combines similarity + property matching)\n",
    "    6. If NO candidate is suitable, select NONE\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    {{\n",
    "      \"selected_entity\": {{\n",
    "        \"index\": selected_index_or_-1_for_none,\n",
    "        \"node_name\": \"selected_node_name_or_NONE\",\n",
    "        \"matching_properties\": [\"property1\", \"property2\"],\n",
    "        \"reason\": \"brief_explanation_focusing_on_property_matches_and_fertility_relevance\"\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You select the most relevant biomedical knowledge graph entity based on property matching and fertility context. Focus on reproductive medicine relevance.\"},\n",
    "                {\"role\": \"user\", \"content\": llm_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        parsed = safe_json_parse(content)\n",
    "        \n",
    "        # Safely access the selected_entity\n",
    "        selected = {}\n",
    "        if isinstance(parsed, dict):\n",
    "            selected = parsed.get(\"selected_entity\", {})\n",
    "        elif isinstance(parsed, list) and len(parsed) > 0:\n",
    "            selected = parsed[0] if isinstance(parsed[0], dict) else {}\n",
    "        \n",
    "        # Safely get index\n",
    "        selected_index = -1\n",
    "        if isinstance(selected, dict):\n",
    "            selected_index = selected.get(\"index\", -1)\n",
    "        else:\n",
    "            # Try to extract index from string\n",
    "            if isinstance(selected, str) and \"index\" in selected.lower():\n",
    "                match = re.search(r'index[\"\\']?\\s*:\\s*(-?\\d+)', selected, re.IGNORECASE)\n",
    "                if match:\n",
    "                    selected_index = int(match.group(1))\n",
    "        \n",
    "        if 0 <= selected_index < len(candidates):\n",
    "            candidate = candidates[selected_index]\n",
    "            \n",
    "            # Safely get matching_properties\n",
    "            matching_properties = []\n",
    "            if isinstance(selected, dict):\n",
    "                matching_properties = selected.get(\"matching_properties\", [])\n",
    "                if not isinstance(matching_properties, list):\n",
    "                    matching_properties = []\n",
    "            \n",
    "            # Safely get reason\n",
    "            reason = \"LLM selected based on biomedical property context\"\n",
    "            if isinstance(selected, dict):\n",
    "                reason = selected.get(\"reason\", reason)\n",
    "            \n",
    "            candidate[\"llm_property_matches\"] = matching_properties\n",
    "            candidate[\"llm_reason\"] = reason\n",
    "            return candidate\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in LLM property matching: {e}\")\n",
    "        if 'content' in locals():\n",
    "            print(f\"   Content: {content[:200]}...\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def map_entity_to_kg_with_properties(entity: Dict, question: str, client) -> Dict:\n",
    "    \"\"\"\n",
    "    Enhanced entity mapping using property-aware pipeline.\n",
    "    \"\"\"\n",
    "    entity_name = entity[\"name\"]\n",
    "    entity_type = entity.get(\"type\", \"Unknown\")\n",
    "    \n",
    "    # Stage 0: Get property-enhanced candidates\n",
    "    candidates = get_enhanced_candidates(entity_name, entity_type, TOP_K)\n",
    "    \n",
    "    if not candidates:\n",
    "        return {\n",
    "            \"query_entity\": entity,\n",
    "            \"mapped_node\": None,\n",
    "            \"mapping_stage\": \"no_candidates\",\n",
    "            \"reason\": \"No similar nodes found in knowledge graph\",\n",
    "            \"property_info\": {}\n",
    "        }\n",
    "    \n",
    "    # Stage 1: Property-based exact match\n",
    "    exact_match = stage1_property_exact_match(entity_name, entity_type, candidates)\n",
    "    if exact_match:\n",
    "        return {\n",
    "            \"query_entity\": entity,\n",
    "            \"mapped_node\": {\n",
    "                \"node_id\": exact_match[\"node_id\"],\n",
    "                \"node_name\": exact_match[\"node_name\"],\n",
    "                \"entity_type\": exact_match.get(\"entity_type\", \"Unknown\"),\n",
    "                \"similarity_score\": exact_match[\"similarity_score\"],\n",
    "                \"enhanced_score\": exact_match.get(\"enhanced_score\", 0),\n",
    "                \"match_type\": exact_match.get(\"match_type\", \"unknown\"),\n",
    "                \"property_match_type\": exact_match.get(\"property_match_type\", \"unknown\"),\n",
    "                \"mapping_stage\": \"property_exact\",\n",
    "                \"reason\": f\"Property-based exact match: {exact_match.get('property_match_type', 'unknown')}\"\n",
    "            },\n",
    "            \"property_info\": exact_match.get(\"property_info\", {})\n",
    "        }\n",
    "    \n",
    "    # Stage 2: Property-enhanced similarity\n",
    "    similarity_match = stage2_property_enhanced_similarity(candidates)\n",
    "    if similarity_match:\n",
    "        return {\n",
    "            \"query_entity\": entity,\n",
    "            \"mapped_node\": {\n",
    "                \"node_id\": similarity_match[\"node_id\"],\n",
    "                \"node_name\": similarity_match[\"node_name\"],\n",
    "                \"entity_type\": similarity_match.get(\"entity_type\", \"Unknown\"),\n",
    "                \"similarity_score\": similarity_match[\"similarity_score\"],\n",
    "                \"enhanced_score\": similarity_match.get(\"enhanced_score\", 0),\n",
    "                \"match_type\": similarity_match.get(\"match_type\", \"unknown\"),\n",
    "                \"mapping_stage\": \"property_enhanced\",\n",
    "                \"reason\": f\"Property-enhanced similarity ({similarity_match.get('match_type', 'unknown')}, score: {similarity_match.get('enhanced_score', 0):.4f})\"\n",
    "            },\n",
    "            \"property_info\": similarity_match.get(\"property_info\", {})\n",
    "        }\n",
    "    \n",
    "    # Stage 3: LLM with property context\n",
    "    llm_match = stage3_property_contextual_llm_match(entity, candidates, question, client)\n",
    "    if llm_match:\n",
    "        return {\n",
    "            \"query_entity\": entity,\n",
    "            \"mapped_node\": {\n",
    "                \"node_id\": llm_match[\"node_id\"],\n",
    "                \"node_name\": llm_match[\"node_name\"],\n",
    "                \"entity_type\": llm_match.get(\"entity_type\", \"Unknown\"),\n",
    "                \"similarity_score\": llm_match[\"similarity_score\"],\n",
    "                \"enhanced_score\": llm_match.get(\"enhanced_score\", 0),\n",
    "                \"match_type\": llm_match.get(\"match_type\", \"unknown\"),\n",
    "                \"mapping_stage\": \"property_llm\",\n",
    "                \"reason\": llm_match.get(\"llm_reason\", \"LLM selected based on property context\"),\n",
    "                \"llm_property_matches\": llm_match.get(\"llm_property_matches\", [])\n",
    "            },\n",
    "            \"property_info\": llm_match.get(\"property_info\", {})\n",
    "        }\n",
    "    \n",
    "    # Fallback: Return best candidate\n",
    "    best_candidate = candidates[0]\n",
    "    return {\n",
    "        \"query_entity\": entity,\n",
    "        \"mapped_node\": {\n",
    "            \"node_id\": best_candidate[\"node_id\"],\n",
    "            \"node_name\": best_candidate[\"node_name\"],\n",
    "            \"entity_type\": best_candidate.get(\"entity_type\", \"Unknown\"),\n",
    "            \"similarity_score\": best_candidate[\"similarity_score\"],\n",
    "            \"enhanced_score\": best_candidate.get(\"enhanced_score\", 0),\n",
    "            \"match_type\": best_candidate.get(\"match_type\", \"unknown\"),\n",
    "            \"mapping_stage\": \"property_fallback\",\n",
    "            \"reason\": f\"No strong property match found. Returning best enhanced match: {best_candidate['node_name']}\"\n",
    "        },\n",
    "        \"property_info\": best_candidate.get(\"property_info\", {})\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94441b27",
   "metadata": {},
   "source": [
    "# PATH SEARCH AND PRUNING FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc7110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths_between_nodes(source_node_id: str, target_node_id: str, max_length: int = MAX_PATH_LENGTH) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Find all paths between two nodes in the knowledge graph.\n",
    "    Returns paths as sequences of nodes and relationships.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            # Find all paths up to max_length hops\n",
    "            result = session.run(\"\"\"\n",
    "            MATCH path = (a)-[*1..%d]-(b)\n",
    "            WHERE elementId(a) = $source_id AND elementId(b) = $target_id\n",
    "            RETURN path, length(path) as pathLength\n",
    "            ORDER BY pathLength ASC\n",
    "            LIMIT 20\n",
    "            \"\"\" % max_length,\n",
    "            source_id=source_node_id, target_id=target_node_id)\n",
    "            \n",
    "            paths = []\n",
    "            seen_paths = set()\n",
    "            \n",
    "            for record in result:\n",
    "                path = record[\"path\"]\n",
    "                path_length = record[\"pathLength\"]\n",
    "                \n",
    "                # Extract nodes and relationships from path\n",
    "                nodes_in_path = []\n",
    "                relationships_in_path = []\n",
    "                \n",
    "                # Get nodes\n",
    "                for node in path.nodes:\n",
    "                    node_props = dict(node)\n",
    "                    node_labels = list(node.labels)\n",
    "                    node_id = str(node.element_id)\n",
    "                    \n",
    "                    # Get node name for display - biomedical context\n",
    "                    node_name = None\n",
    "                    \n",
    "                    # Try biomedical property names first\n",
    "                    for prop_name in [\n",
    "    # Disease-specific properties\n",
    "    \"SNOMEDCT_US_definition\",\n",
    "    \"mayo_causes\",\n",
    "    \"mayo_complications\",\n",
    "    \"mayo_prevention\",\n",
    "    \"mayo_risk_factors\",\n",
    "    \"mayo_see_doc\",\n",
    "    \"mayo_symptoms\",\n",
    "    \"mondo_definitions\",\n",
    "    \"orphanet_clinical_description\",\n",
    "    \"orphanet_definition\",\n",
    "    \"orphanet_epidemiology\",\n",
    "    \"orphanet_management_and_treatment\",\n",
    "    \"orphanet_prevalence\",\n",
    "    \"umls_descriptions\",\n",
    "    \n",
    "    # Drug-specific properties\n",
    "    \"atc_4\",\n",
    "    \"category\",\n",
    "    \"clogp\",\n",
    "    \"description\",\n",
    "    \"group\",\n",
    "    \"half_life\",\n",
    "    \"indication\",\n",
    "    \"mechanism_of_action\",\n",
    "    \"molecular_weight\",\n",
    "    \"pathway\",\n",
    "    \"pharmacodynamics\",\n",
    "    \"protein_binding\",\n",
    "    \"state\",\n",
    "    \"tpsa\",\n",
    "    \n",
    "    # Common properties (appear in both)\n",
    "    \"node_id\",\n",
    "    \"node_index\",\n",
    "    \"node_name\",\n",
    "    \"node_source\"\n",
    "]:\n",
    "                        if prop_name in node_props and node_props[prop_name]:\n",
    "                            node_name = str(node_props[prop_name])\n",
    "                            # Truncate if too long\n",
    "                            if len(node_name) > 100:\n",
    "                                node_name = node_name[:100] + \"...\"\n",
    "                            break\n",
    "                    \n",
    "                    # Fallback to any property\n",
    "                    if not node_name and node_props:\n",
    "                        for prop_value in node_props.values():\n",
    "                            if prop_value:\n",
    "                                node_name = str(prop_value)\n",
    "                                if len(node_name) > 100:\n",
    "                                    node_name = node_name[:100] + \"...\"\n",
    "                                break\n",
    "                    \n",
    "                    nodes_in_path.append({\n",
    "                        \"id\": node_id,\n",
    "                        \"labels\": node_labels,\n",
    "                        \"name\": node_name or f\"Node_{node_id}\",\n",
    "                        \"properties\": node_props\n",
    "                    })\n",
    "                \n",
    "                # Get relationships\n",
    "                for rel in path.relationships:\n",
    "                    rel_type = rel.type\n",
    "                    rel_props = dict(rel)\n",
    "                    \n",
    "                    relationships_in_path.append({\n",
    "                        \"type\": rel_type,\n",
    "                        \"properties\": rel_props\n",
    "                    })\n",
    "                \n",
    "                # Create path string representation\n",
    "                path_string_parts = []\n",
    "                for i, node in enumerate(nodes_in_path):\n",
    "                    path_string_parts.append(node[\"name\"])\n",
    "                    if i < len(relationships_in_path):\n",
    "                        rel = relationships_in_path[i]\n",
    "                        path_string_parts.append(f\"--[{rel['type']}]-->\")\n",
    "                \n",
    "                path_string = \" \".join(path_string_parts)\n",
    "                \n",
    "                # Create unique signature to avoid duplicates\n",
    "                path_signature = path_string\n",
    "                \n",
    "                if path_signature not in seen_paths:\n",
    "                    seen_paths.add(path_signature)\n",
    "                    \n",
    "                    paths.append({\n",
    "                        \"path_string\": path_string,\n",
    "                        \"path_length\": path_length,\n",
    "                        \"nodes\": nodes_in_path,\n",
    "                        \"relationships\": relationships_in_path,\n",
    "                        \"source_node\": nodes_in_path[0],\n",
    "                        \"target_node\": nodes_in_path[-1],\n",
    "                        \"detailed_description\": generate_detailed_path_description(nodes_in_path, relationships_in_path)\n",
    "                    })\n",
    "            \n",
    "            return paths\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error finding paths: {e}\")\n",
    "            return []\n",
    "\n",
    "def generate_detailed_path_description(nodes: List[Dict], relationships: List[Dict]) -> str:\n",
    "    \"\"\"Generate a natural language description of the path.\"\"\"\n",
    "    description_parts = []\n",
    "    \n",
    "    for i, (node, rel) in enumerate(zip(nodes[:-1], relationships)):\n",
    "        # Node description - biomedical context\n",
    "        labels_str = ', '.join(node['labels'])\n",
    "        if not labels_str:\n",
    "            labels_str = \"Unknown\"\n",
    "        node_desc = f\"{node['name']} ({labels_str})\"\n",
    "        \n",
    "        # Relationship description - keep biomedical terms\n",
    "        rel_desc = rel['type'].lower().replace('_', ' ')\n",
    "        \n",
    "        description_parts.append(f\"{node_desc} {rel_desc}\")\n",
    "    \n",
    "    # Add last node\n",
    "    if nodes:\n",
    "        last_node = nodes[-1]\n",
    "        labels_str = ', '.join(last_node['labels'])\n",
    "        if not labels_str:\n",
    "            labels_str = \"Unknown\"\n",
    "        last_node_desc = f\"{last_node['name']} ({labels_str})\"\n",
    "        description_parts.append(last_node_desc)\n",
    "    \n",
    "    return \" â†’ \".join(description_parts)\n",
    "\n",
    "def prune_paths_with_llm(question: str, all_paths: List[Dict], entity_mappings: List[Dict], client) -> Dict:\n",
    "    \"\"\"\n",
    "    Use LLM to select the most relevant path for answering the question.\n",
    "    \"\"\"\n",
    "    if not all_paths:\n",
    "        return {\"selected_path\": None, \"reasoning\": \"No paths found\"}\n",
    "    \n",
    "    # Prepare entity mapping information\n",
    "    entity_info = []\n",
    "    for mapping in entity_mappings:\n",
    "        if mapping.get(\"mapped_node\"):\n",
    "            entity = mapping[\"query_entity\"]\n",
    "            mapped = mapping[\"mapped_node\"]\n",
    "            entity_info.append({\n",
    "                \"query_entity\": entity[\"name\"],\n",
    "                \"entity_type\": entity.get(\"type\", \"Unknown\"),\n",
    "                \"mapped_to\": mapped[\"node_name\"],\n",
    "                \"mapping_confidence\": mapped.get(\"enhanced_score\", 0),\n",
    "                \"mapping_stage\": mapped.get(\"mapping_stage\", \"unknown\")\n",
    "            })\n",
    "    \n",
    "    # Prepare path candidates for LLM evaluation\n",
    "    path_candidates = []\n",
    "    for i, path in enumerate(all_paths[:TOP_PATHS_FOR_PRUNING]):\n",
    "        # Calculate path relevance score (combine length and entity coverage)\n",
    "        entity_coverage = 0\n",
    "        for mapping in entity_mappings:\n",
    "            if mapping.get(\"mapped_node\"):\n",
    "                mapped_name = mapping[\"mapped_node\"][\"node_name\"]\n",
    "                # Check if this entity appears in the path\n",
    "                for node in path[\"nodes\"]:\n",
    "                    if node[\"name\"] == mapped_name:\n",
    "                        entity_coverage += 1\n",
    "                        break\n",
    "        \n",
    "        path_relevance_score = entity_coverage / max(len(entity_mappings), 1)\n",
    "        \n",
    "        # Calculate biomedical relevance score based on labels\n",
    "        biomedical_relevance = 0\n",
    "        fertility_keywords = [\"disease\", \"drug\", \"gene\", \"protein\", \"pathway\", \n",
    "                            \"treatment\", \"therapy\", \"infertility\", \"fertility\"]\n",
    "        \n",
    "        for node in path[\"nodes\"]:\n",
    "            labels_lower = [label.lower() for label in node[\"labels\"]]\n",
    "            for keyword in fertility_keywords:\n",
    "                if any(keyword in label for label in labels_lower):\n",
    "                    biomedical_relevance += 1\n",
    "                    break\n",
    "        \n",
    "        path_candidates.append({\n",
    "            \"path_id\": i + 1,\n",
    "            \"path_string\": path[\"path_string\"],\n",
    "            \"path_length\": path[\"path_length\"],\n",
    "            \"detailed_description\": path.get(\"detailed_description\", path[\"path_string\"]),\n",
    "            \"entity_coverage\": entity_coverage,\n",
    "            \"relevance_score\": round(path_relevance_score, 2),\n",
    "            \"biomedical_relevance\": biomedical_relevance\n",
    "        })\n",
    "    \n",
    "    # Create LLM prompt for path pruning - BIOMEDICAL CONTEXT\n",
    "    pruning_prompt = f\"\"\"\n",
    "    You are a biomedical knowledge graph expert specializing in fertility and reproductive medicine. \n",
    "    Select the most relevant path for answering the given clinical question.\n",
    "\n",
    "    CLINICAL QUESTION: \"{question}\"\n",
    "\n",
    "    ENTITY MAPPINGS (from question to knowledge graph):\n",
    "    {json.dumps(entity_info, indent=2)}\n",
    "\n",
    "    AVAILABLE PATHS in knowledge graph:\n",
    "    {json.dumps(path_candidates, indent=2)}\n",
    "\n",
    "    SELECTION CRITERIA FOR BIOMEDICAL CONTEXT:\n",
    "    1. CLINICAL RELEVANCE: Does the path directly address the clinical question about fertility?\n",
    "    2. ENTITY COVERAGE: Does the path include all/most mapped clinical entities?\n",
    "    3. BIOMEDICAL COHERENCE: Does the path make biological/medical sense?\n",
    "    4. PATH LENGTH: Shorter paths are preferred for clarity\n",
    "    5. FERTILITY CONTEXT: Does the path involve fertility-related concepts?\n",
    "        - Disease-drug relationships\n",
    "        - Treatment pathways\n",
    "        - Biological mechanisms\n",
    "        - Clinical outcomes\n",
    "\n",
    "    OUTPUT FORMAT:\n",
    "    {{\n",
    "      \"selected_path\": {{\n",
    "        \"path_id\": selected_path_number,\n",
    "        \"path_string\": \"selected_path_string\",\n",
    "        \"reasoning\": \"detailed_explanation_focusing_on_biomedical_relevance_and_fertility_context\",\n",
    "        \"confidence_score\": 0.0_to_1.0\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    If no path is clinically relevant, set \"path_id\" to -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You select the most relevant biomedical knowledge graph path for answering fertility-related clinical questions. Focus on clinical relevance and biological plausibility.\"},\n",
    "                {\"role\": \"user\", \"content\": pruning_prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=600\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        parsed = safe_json_parse(content)\n",
    "        \n",
    "        if not parsed:\n",
    "            # Fallback: select shortest path with best entity coverage\n",
    "            return select_best_path_fallback(path_candidates, entity_mappings)\n",
    "        \n",
    "        selected_path = parsed.get(\"selected_path\", {})\n",
    "        path_id = selected_path.get(\"path_id\", -1)\n",
    "        \n",
    "        if 1 <= path_id <= len(all_paths):\n",
    "            selected_path_data = all_paths[path_id - 1]\n",
    "            \n",
    "            # Add LLM reasoning to the path\n",
    "            selected_path_data[\"llm_selected\"] = True\n",
    "            selected_path_data[\"selection_reasoning\"] = selected_path.get(\"reasoning\", \"LLM selected\")\n",
    "            selected_path_data[\"selection_confidence\"] = selected_path.get(\"confidence_score\", 0.8)\n",
    "            \n",
    "            return {\n",
    "                \"selected_path\": selected_path_data,\n",
    "                \"reasoning\": selected_path.get(\"reasoning\", \"Path selected by LLM for clinical relevance\"),\n",
    "                \"confidence\": selected_path.get(\"confidence_score\", 0.8),\n",
    "                \"all_considered_paths\": path_candidates\n",
    "            }\n",
    "        else:\n",
    "            return select_best_path_fallback(path_candidates, entity_mappings)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in LLM path pruning: {e}\")\n",
    "        return select_best_path_fallback(path_candidates, entity_mappings)\n",
    "\n",
    "def select_best_path_fallback(path_candidates: List[Dict], entity_mappings: List[Dict]) -> Dict:\n",
    "    \"\"\"Fallback method to select best path when LLM fails.\"\"\"\n",
    "    if not path_candidates:\n",
    "        return {\"selected_path\": None, \"reasoning\": \"No paths available\"}\n",
    "    \n",
    "    # Score each path\n",
    "    scored_paths = []\n",
    "    for path in path_candidates:\n",
    "        score = 0\n",
    "        \n",
    "        # Preference for shorter paths\n",
    "        length_score = 1.0 / (path[\"path_length\"] + 1)\n",
    "        \n",
    "        # Preference for higher entity coverage\n",
    "        coverage_score = path[\"entity_coverage\"] / max(len(entity_mappings), 1)\n",
    "        \n",
    "        # Preference for biomedical relevance\n",
    "        biomedical_score = path.get(\"biomedical_relevance\", 0) / max(len(path.get(\"nodes\", [])), 1)\n",
    "        \n",
    "        # Combined score - weighted\n",
    "        total_score = (length_score * 0.3) + (coverage_score * 0.4) + (biomedical_score * 0.3)\n",
    "        \n",
    "        scored_paths.append((total_score, path))\n",
    "    \n",
    "    # Select best path\n",
    "    scored_paths.sort(key=lambda x: x[0], reverse=True)\n",
    "    best_score, best_path = scored_paths[0]\n",
    "    \n",
    "    return {\n",
    "        \"selected_path\": best_path,\n",
    "        \"reasoning\": f\"Fallback: Selected path with best entity coverage ({best_path['entity_coverage']}/{len(entity_mappings)}), biomedical relevance ({best_path.get('biomedical_relevance', 0)}), and length {best_path['path_length']}\",\n",
    "        \"confidence\": round(best_score, 2),\n",
    "        \"all_considered_paths\": path_candidates\n",
    "    }\n",
    "\n",
    "def find_shortest_paths_between_entities(mapped_entities: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Find shortest paths between all pairs of successfully mapped entities.\n",
    "    \"\"\"\n",
    "    path_results = {\n",
    "        \"entity_pairs\": [],\n",
    "        \"total_paths_found\": 0,\n",
    "        \"all_paths\": []\n",
    "    }\n",
    "    \n",
    "    # Get successfully mapped nodes\n",
    "    successful_mappings = [\n",
    "        mapping for mapping in mapped_entities \n",
    "        if mapping.get(\"mapped_node\") and mapping[\"mapped_node\"].get(\"node_id\")\n",
    "    ]\n",
    "    \n",
    "    if len(successful_mappings) < 2:\n",
    "        return path_results\n",
    "    \n",
    "    print(f\"\\nðŸ” Searching paths between {len(successful_mappings)} mapped biomedical entities...\")\n",
    "    \n",
    "    # Find paths for each pair\n",
    "    for i in range(len(successful_mappings)):\n",
    "        for j in range(i + 1, len(successful_mappings)):\n",
    "            mapping1 = successful_mappings[i]\n",
    "            mapping2 = successful_mappings[j]\n",
    "            \n",
    "            source_id = mapping1[\"mapped_node\"][\"node_id\"]\n",
    "            target_id = mapping2[\"mapped_node\"][\"node_id\"]\n",
    "            source_name = mapping1[\"query_entity\"][\"name\"]\n",
    "            target_name = mapping2[\"query_entity\"][\"name\"]\n",
    "            source_type = mapping1[\"query_entity\"].get(\"type\", \"Unknown\")\n",
    "            target_type = mapping2[\"query_entity\"].get(\"type\", \"Unknown\")\n",
    "            \n",
    "            print(f\"  ðŸ”— {source_name} ({source_type}) â†’ {target_name} ({target_type})...\")\n",
    "            \n",
    "            paths = find_paths_between_nodes(source_id, target_id)\n",
    "            \n",
    "            if paths:\n",
    "                # Sort by path length and take top N\n",
    "                paths.sort(key=lambda x: x[\"path_length\"])\n",
    "                top_paths = paths[:MAX_PATHS_PER_PAIR]\n",
    "                \n",
    "                pair_result = {\n",
    "                    \"source_entity\": source_name,\n",
    "                    \"target_entity\": target_name,\n",
    "                    \"source_type\": source_type,\n",
    "                    \"target_type\": target_type,\n",
    "                    \"source_node\": mapping1[\"mapped_node\"][\"node_name\"],\n",
    "                    \"target_node\": mapping2[\"mapped_node\"][\"node_name\"],\n",
    "                    \"paths_found\": len(paths),\n",
    "                    \"shortest_path_length\": paths[0][\"path_length\"] if paths else None,\n",
    "                    \"top_paths\": top_paths\n",
    "                }\n",
    "                \n",
    "                path_results[\"entity_pairs\"].append(pair_result)\n",
    "                path_results[\"total_paths_found\"] += len(paths)\n",
    "                path_results[\"all_paths\"].extend(top_paths)\n",
    "                \n",
    "                print(f\"    âœ… Found {len(paths)} paths (showing {len(top_paths)})\")\n",
    "                for path in top_paths[:2]:  # Show first 2 paths\n",
    "                    print(f\"       â€¢ {path['path_string']}\")\n",
    "            else:\n",
    "                print(f\"    âŒ No paths found\")\n",
    "    \n",
    "    return path_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a296bfa3",
   "metadata": {},
   "source": [
    "# CHAIN-OF-THOUGHT (COT) GENERATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd88448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chain_of_thought(question: str, selected_path: Dict, entity_mappings: List[Dict], client) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate Chain-of-Thought reasoning based on the selected biomedical path.\n",
    "    \"\"\"\n",
    "    if not selected_path:\n",
    "        return {\n",
    "            \"cot\": \"No relevant path found to generate reasoning.\",\n",
    "            \"reasoning_steps\": [],\n",
    "            \"final_answer\": \"Cannot answer based on available biomedical knowledge graph information.\"\n",
    "        }\n",
    "    \n",
    "    # Extract path information\n",
    "    path_description = selected_path.get(\"detailed_description\", selected_path[\"path_string\"])\n",
    "    nodes = selected_path.get(\"nodes\", [])\n",
    "    relationships = selected_path.get(\"relationships\", [])\n",
    "    \n",
    "    # Prepare entity context\n",
    "    entity_context = []\n",
    "    for mapping in entity_mappings:\n",
    "        if mapping.get(\"mapped_node\"):\n",
    "            entity = mapping[\"query_entity\"]\n",
    "            mapped = mapping[\"mapped_node\"]\n",
    "            entity_context.append({\n",
    "                \"mentioned_in_question\": entity[\"name\"],\n",
    "                \"mapped_to_knowledge_graph\": mapped[\"node_name\"],\n",
    "                \"entity_type\": entity.get(\"type\", \"Unknown\"),\n",
    "                \"mapping_confidence\": round(mapped.get(\"enhanced_score\", 0), 3)\n",
    "            })\n",
    "    \n",
    "    # Prepare path nodes information for biomedical context\n",
    "    path_nodes_info = []\n",
    "    for i, node in enumerate(nodes):\n",
    "        node_info = {\n",
    "            \"step\": i + 1,\n",
    "            \"node_name\": node[\"name\"],\n",
    "            \"node_labels\": node[\"labels\"],\n",
    "            \"role_in_path\": \"Source\" if i == 0 else \"Target\" if i == len(nodes)-1 else \"Intermediate\"\n",
    "        }\n",
    "        \n",
    "        # Add biomedical context based on labels and properties\n",
    "        props = node.get(\"properties\", {})\n",
    "        \n",
    "        # Check for disease properties\n",
    "        disease_props = [\"mondo_definitions\", \"mayo_symptoms\", \"orphanet_definition\"]\n",
    "        for prop in disease_props:\n",
    "            if prop in props:\n",
    "                node_info[\"disease_info\"] = f\"Has {prop}: {str(props[prop])[:100]}...\"\n",
    "                break\n",
    "        \n",
    "        # Check for drug properties\n",
    "        drug_props = [\"description\", \"indication\", \"mechanism_of_action\"]\n",
    "        for prop in drug_props:\n",
    "            if prop in props:\n",
    "                node_info[\"drug_info\"] = f\"Has {prop}: {str(props[prop])[:100]}...\"\n",
    "                break\n",
    "        \n",
    "        # Add fertility relevance\n",
    "        fertility_keywords = [\"fertility\", \"infertility\", \"ovarian\", \"uterine\", \"sperm\", \"egg\", \"embryo\", \"pregnancy\"]\n",
    "        node_text = json.dumps(node).lower()\n",
    "        fertility_mentions = [kw for kw in fertility_keywords if kw in node_text]\n",
    "        if fertility_mentions:\n",
    "            node_info[\"fertility_relevance\"] = f\"Mentions: {', '.join(fertility_mentions[:3])}\"\n",
    "        \n",
    "        path_nodes_info.append(node_info)\n",
    "    \n",
    "    # Prepare relationships information\n",
    "    relationships_info = []\n",
    "    for i, rel in enumerate(relationships):\n",
    "        rel_info = {\n",
    "            \"step\": i + 1,\n",
    "            \"relationship_type\": rel[\"type\"],\n",
    "            \"biomedical_meaning\": translate_biomedical_relationship(rel[\"type\"]),\n",
    "            \"connects\": f\"{nodes[i]['name']} â†’ {nodes[i+1]['name']}\"\n",
    "        }\n",
    "        \n",
    "        # Check if relationship has fertility relevance\n",
    "        rel_text = json.dumps(rel).lower()\n",
    "        fertility_rel_keywords = [\"treats\", \"causes\", \"associated\", \"targets\", \"interacts\", \"regulates\"]\n",
    "        if any(kw in rel_text for kw in fertility_rel_keywords):\n",
    "            rel_info[\"fertility_context\"] = \"May relate to fertility mechanisms\"\n",
    "            \n",
    "        relationships_info.append(rel_info)\n",
    "    \n",
    "    # Create CoT generation prompt for biomedical context\n",
    "    cot_prompt = f\"\"\"\n",
    "    CLINICAL QUESTION: \"{question}\"\n",
    "\n",
    "    ENTITY MAPPING CONTEXT (question entities mapped to knowledge graph):\n",
    "    {json.dumps(entity_context, indent=2)}\n",
    "\n",
    "    SELECTED BIOMEDICAL KNOWLEDGE GRAPH PATH:\n",
    "    Path Description: {path_description}\n",
    "    \n",
    "    Detailed Path Analysis:\n",
    "    1. PATH NODES (biomedical entities):\n",
    "    {json.dumps(path_nodes_info, indent=2)}\n",
    "    \n",
    "    2. BIOLOGICAL RELATIONSHIPS:\n",
    "    {json.dumps(relationships_info, indent=2)}\n",
    "\n",
    "    TASK: Generate a Chain-of-Thought (CoT) reasoning to answer the clinical question based on the biomedical knowledge graph path.\n",
    "\n",
    "    COT STRUCTURE FOR BIOMEDICAL CONTEXT:\n",
    "    1. CLINICAL ENTITY IDENTIFICATION: Identify which clinical entities from the question are present in the path\n",
    "    2. PATH BIOLOGICAL INTERPRETATION: Explain what the path means in biological/medical terms\n",
    "    3. RELATIONSHIP ANALYSIS: Analyze each biological relationship in the context of fertility/medicine\n",
    "    4. CLINICAL INFERENCE: Draw logical clinical conclusions from the path\n",
    "    5. ANSWER: Provide a concise clinical answer based on the reasoning\n",
    "\n",
    "    IMPORTANT FOR FERTILITY CONTEXT:\n",
    "    - Focus on reproductive health implications\n",
    "    - Consider disease-drug relationships\n",
    "    - Mention fertility relevance when applicable\n",
    "    - Base reasoning ONLY on the specific path shown above\n",
    "\n",
    "    OUTPUT FORMAT:\n",
    "    {{\n",
    "      \"chain_of_thought\": {{\n",
    "        \"reasoning_steps\": [\n",
    "          \"Step 1: Identify clinical entities from question that appear in the path\",\n",
    "          \"Step 2: Explain the first biological relationship in medical terms\",\n",
    "          \"Step 3: Explain subsequent biological relationships\",\n",
    "          \"Step 4: Draw clinical conclusions based on the complete path\",\n",
    "          \"Step 5: Formulate the clinical answer\"\n",
    "        ],\n",
    "        \"detailed_reasoning\": \"Multi-paragraph detailed explanation connecting the path to the clinical question\",\n",
    "        \"final_answer\": \"Concise clinical answer to the original question\"\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a clinical researcher that generates detailed Chain-of-Thought reasoning based on biomedical knowledge graph paths. Specialize in fertility and reproductive medicine. Be precise and reference specific biological entities and relationships.\"},\n",
    "                {\"role\": \"user\", \"content\": cot_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=800\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        parsed = safe_json_parse(content)\n",
    "        \n",
    "        if not parsed:\n",
    "            # Generate fallback CoT\n",
    "            return generate_fallback_biomedical_cot(question, selected_path, entity_mappings)\n",
    "        \n",
    "        cot_data = parsed.get(\"chain_of_thought\", {})\n",
    "        \n",
    "        # Ensure we have the required structure\n",
    "        if not cot_data.get(\"reasoning_steps\"):\n",
    "            cot_data[\"reasoning_steps\"] = [\n",
    "                f\"Step 1: The path connects {selected_path['source_node']['name']} to {selected_path['target_node']['name']}\",\n",
    "                f\"Step 2: The biological relationship is {selected_path['relationships'][0]['type'] if selected_path.get('relationships') else 'unknown'}\",\n",
    "                \"Step 3: This indicates a biomedical connection between the entities\",\n",
    "                \"Step 4: Based on this connection, we can infer clinical implications\",\n",
    "                \"Step 5: Clinical answer formulated from path analysis\"\n",
    "            ]\n",
    "        \n",
    "        if not cot_data.get(\"detailed_reasoning\"):\n",
    "            cot_data[\"detailed_reasoning\"] = generate_biomedical_path_based_reasoning(selected_path, question)\n",
    "        \n",
    "        if not cot_data.get(\"final_answer\"):\n",
    "            cot_data[\"final_answer\"] = generate_biomedical_final_answer(selected_path, question)\n",
    "        \n",
    "        return cot_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in CoT generation: {e}\")\n",
    "        return generate_fallback_biomedical_cot(question, selected_path, entity_mappings)\n",
    "\n",
    "def translate_biomedical_relationship(rel_type: str) -> str:\n",
    "    \"\"\"Translate relationship type to biomedical meaning.\"\"\"\n",
    "    translations = {\n",
    "        \"ASSOCIATED_WITH\": \"is clinically associated with\",\n",
    "        \"TREATS\": \"is used to treat\",\n",
    "        \"CAUSES\": \"can cause or contribute to\",\n",
    "        \"INTERACTS_WITH\": \"biologically interacts with\",\n",
    "        \"REGULATES\": \"regulates or modulates\",\n",
    "        \"TARGETS\": \"targets or affects\",\n",
    "        \"INDUCES\": \"induces or triggers\",\n",
    "        \"INHIBITS\": \"inhibits or blocks\",\n",
    "        \"ENHANCES\": \"enhances or increases\",\n",
    "        \"PREDISPOSES\": \"predisposes to or increases risk of\",\n",
    "        \"PART_OF\": \"is part of biological pathway\",\n",
    "        \"ENCODES\": \"encodes or produces\",\n",
    "        \"METABOLIZES\": \"metabolizes or breaks down\",\n",
    "        \"BINDS_TO\": \"binds to or interacts with\",\n",
    "        \"UPREGULATES\": \"upregulates or increases expression of\",\n",
    "        \"DOWNREGULATES\": \"downregulates or decreases expression of\"\n",
    "    }\n",
    "    return translations.get(rel_type, f\"has biological relationship: {rel_type.lower().replace('_', ' ')}\")\n",
    "\n",
    "def generate_biomedical_path_based_reasoning(path: Dict, question: str) -> str:\n",
    "    \"\"\"Generate clinical reasoning based on path structure.\"\"\"\n",
    "    if not path:\n",
    "        return \"No path available for clinical reasoning.\"\n",
    "    \n",
    "    path_desc = path.get(\"detailed_description\", path.get(\"path_string\", \"\"))\n",
    "    nodes = path.get(\"nodes\", [])\n",
    "    \n",
    "    reasoning = f\"Analyzing the biomedical path: {path_desc}\\n\\n\"\n",
    "    \n",
    "    if len(nodes) >= 2:\n",
    "        # Extract actual node names\n",
    "        node_names = []\n",
    "        for node in nodes:\n",
    "            name = node.get(\"name\", \"Unknown\")\n",
    "            # Clean up the name\n",
    "            name = name.split(\" --[\")[0] if \" --[\" in name else name\n",
    "            node_names.append(name)\n",
    "        \n",
    "        reasoning += f\"The clinical path connects {node_names[0]} \"\n",
    "        \n",
    "        for i, rel in enumerate(path.get(\"relationships\", [])):\n",
    "            rel_meaning = translate_biomedical_relationship(rel['type'])\n",
    "            reasoning += f\"which {rel_meaning} {node_names[i+1]} \"\n",
    "        \n",
    "        reasoning += f\"\\n\\nThis path shows a direct biomedical relationship between the clinical entities mentioned in the question.\"\n",
    "        \n",
    "        # Add fertility context if relevant\n",
    "        question_lower = question.lower()\n",
    "        path_text = json.dumps(path).lower()\n",
    "        fertility_terms = [\"fertility\", \"infertility\", \"pregnancy\", \"reproductive\", \"ovarian\", \"sperm\"]\n",
    "        \n",
    "        if any(term in question_lower for term in fertility_terms) or any(term in path_text for term in fertility_terms):\n",
    "            reasoning += \" This relationship is particularly relevant to fertility and reproductive health.\"\n",
    "    \n",
    "    return reasoning\n",
    "\n",
    "def generate_biomedical_final_answer(path: Dict, question: str) -> str:\n",
    "    \"\"\"Generate clinical final answer based on path.\"\"\"\n",
    "    if not path:\n",
    "        return \"Based on the available biomedical knowledge graph, no direct clinical relationship was found to answer the question.\"\n",
    "    \n",
    "    # Get the path string and nodes\n",
    "    path_string = path.get(\"path_string\", \"\")\n",
    "    nodes = path.get(\"nodes\", [])\n",
    "    \n",
    "    # Extract source and target node names\n",
    "    source_name = \"Unknown\"\n",
    "    target_name = \"Unknown\"\n",
    "    \n",
    "    if nodes:\n",
    "        source_name = nodes[0].get(\"name\", \"Unknown\") if nodes else \"Unknown\"\n",
    "        target_name = nodes[-1].get(\"name\", \"Unknown\") if nodes else \"Unknown\"\n",
    "    \n",
    "    # Clean up node names\n",
    "    source_name = source_name.split(\" --[\")[0] if \" --[\" in source_name else source_name\n",
    "    target_name = target_name.split(\" --[\")[0] if \" --[\" in target_name else target_name\n",
    "    \n",
    "    # Get relationship information\n",
    "    relationships = path.get(\"relationships\", [])\n",
    "    rel_info = \"\"\n",
    "    if relationships:\n",
    "        rel_type = relationships[0].get(\"type\", \"connected\")\n",
    "        rel_meaning = translate_biomedical_relationship(rel_type)\n",
    "        rel_info = f\" {rel_meaning} \"\n",
    "    \n",
    "    # Generate appropriate answer based on question\n",
    "    question_lower = question.lower()\n",
    "    \n",
    "    # Fertility-specific patterns\n",
    "    if any(term in question_lower for term in [\"fertility\", \"infertility\", \"reproductive\"]):\n",
    "        if \"drug\" in question_lower or \"treatment\" in question_lower or \"treat\" in question_lower:\n",
    "            return f\"Yes, {source_name}{rel_info}{target_name} in the context of fertility treatment.\"\n",
    "        elif \"cause\" in question_lower or \"risk\" in question_lower:\n",
    "            return f\"Yes, {source_name}{rel_info}{target_name}, which may impact fertility.\"\n",
    "        else:\n",
    "            return f\"Yes, there is a biomedical relationship between {source_name} and {target_name} relevant to fertility.\"\n",
    "    \n",
    "    # Disease-drug patterns\n",
    "    elif \"disease\" in question_lower and \"drug\" in question_lower:\n",
    "        if \"treat\" in question_lower or \"effective\" in question_lower:\n",
    "            return f\"Yes, {target_name}{rel_info}{source_name} for treatment.\"\n",
    "        elif \"side effect\" in question_lower or \"risk\" in question_lower:\n",
    "            return f\"Yes, {source_name}{rel_info}{target_name}, which may have clinical implications.\"\n",
    "        else:\n",
    "            return f\"Yes, {source_name}{rel_info}{target_name} in the knowledge graph.\"\n",
    "    \n",
    "    # General biomedical relationship\n",
    "    elif \"relationship\" in question_lower or \"connect\" in question_lower or \"associate\" in question_lower:\n",
    "        return f\"Yes, {source_name}{rel_info}{target_name} in the biomedical knowledge graph.\"\n",
    "    \n",
    "    else:\n",
    "        # Generic biomedical answer\n",
    "        return f\"Yes, {source_name} is biologically connected to {target_name} in the knowledge graph.\"\n",
    "\n",
    "def generate_fallback_biomedical_cot(question: str, selected_path: Dict, entity_mappings: List[Dict]) -> Dict:\n",
    "    \"\"\"Generate fallback biomedical Chain-of-Thought when LLM fails.\"\"\"\n",
    "    if not selected_path:\n",
    "        return {\n",
    "            \"chain_of_thought\": {\n",
    "                \"reasoning_steps\": [\"No clinical path available for reasoning\"],\n",
    "                \"detailed_reasoning\": \"Cannot generate clinical reasoning without a valid biomedical knowledge graph path.\",\n",
    "                \"final_answer\": \"Insufficient information in biomedical knowledge graph to answer the clinical question.\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Get node names from the path\n",
    "    nodes = selected_path.get(\"nodes\", [])\n",
    "    source_name = \"Unknown\"\n",
    "    target_name = \"Unknown\"\n",
    "    \n",
    "    if nodes:\n",
    "        source_name = nodes[0].get(\"name\", \"Unknown\")\n",
    "        target_name = nodes[-1].get(\"name\", \"Unknown\")\n",
    "        # Clean names\n",
    "        source_name = source_name.split(\" --[\")[0] if \" --[\" in source_name else source_name\n",
    "        target_name = target_name.split(\" --[\")[0] if \" --[\" in target_name else target_name\n",
    "    \n",
    "    # Get entity names from mappings\n",
    "    entity_names = []\n",
    "    for mapping in entity_mappings:\n",
    "        if mapping.get(\"query_entity\"):\n",
    "            entity_names.append(mapping[\"query_entity\"][\"name\"])\n",
    "    \n",
    "    path_desc = selected_path.get(\"detailed_description\", selected_path.get(\"path_string\", \"\"))\n",
    "    \n",
    "    # Get relationship information for biomedical context\n",
    "    relationships = selected_path.get(\"relationships\", [])\n",
    "    rel_text = \"\"\n",
    "    if relationships:\n",
    "        rel_type = relationships[0].get(\"type\", \"connected\")\n",
    "        rel_meaning = translate_biomedical_relationship(rel_type)\n",
    "        rel_text = f\" through {rel_meaning}\"\n",
    "    \n",
    "    reasoning_steps = [\n",
    "        f\"Step 1: Identified clinical entities in question: {', '.join(entity_names)}\",\n",
    "        f\"Step 2: Found biomedical knowledge graph path connecting {source_name} to {target_name}{rel_text}\",\n",
    "        f\"Step 3: Path length: {selected_path.get('path_length', 'N/A')} biological relationships\",\n",
    "        f\"Step 4: The path shows that {source_name} is biologically connected to {target_name}\",\n",
    "        f\"Step 5: Based on this biomedical connection, we can answer the clinical question\"\n",
    "    ]\n",
    "    \n",
    "    detailed_reasoning = generate_biomedical_path_based_reasoning(selected_path, question)\n",
    "    final_answer = generate_biomedical_final_answer(selected_path, question)\n",
    "    \n",
    "    return {\n",
    "        \"chain_of_thought\": {\n",
    "            \"reasoning_steps\": reasoning_steps,\n",
    "            \"detailed_reasoning\": detailed_reasoning,\n",
    "            \"final_answer\": final_answer\n",
    "        }\n",
    "    }\n",
    "\n",
    "def format_biomedical_paths_for_display(path_results: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Format biomedical path results in a readable way.\n",
    "    \"\"\"\n",
    "    if not path_results[\"entity_pairs\"]:\n",
    "        return \"No clinical paths found between mapped entities.\"\n",
    "    \n",
    "    output_lines = []\n",
    "    output_lines.append(\"\\n\" + \"=\"*80)\n",
    "    output_lines.append(\"BIOMEDICAL PATH SEARCH RESULTS\")\n",
    "    output_lines.append(\"=\"*80)\n",
    "    \n",
    "    output_lines.append(f\"\\nTotal clinical entity pairs analyzed: {len(path_results['entity_pairs'])}\")\n",
    "    output_lines.append(f\"Total biomedical paths found: {path_results['total_paths_found']}\")\n",
    "    \n",
    "    for pair_idx, pair in enumerate(path_results[\"entity_pairs\"], 1):\n",
    "        output_lines.append(f\"\\n{pair_idx}. {pair['source_entity']} ({pair['source_type']}) â†’ {pair['target_entity']} ({pair['target_type']})\")\n",
    "        output_lines.append(f\"   Mapped to KG: {pair['source_node']} â†’ {pair['target_node']}\")\n",
    "        output_lines.append(f\"   Paths found: {pair['paths_found']}\")\n",
    "        output_lines.append(f\"   Shortest path length: {pair['shortest_path_length']} biological relationships\")\n",
    "        \n",
    "        for path_idx, path in enumerate(pair[\"top_paths\"][:2], 1):  # Show first 2 paths\n",
    "            output_lines.append(f\"\\n   Path {path_idx} ({path['path_length']} hops):\")\n",
    "            output_lines.append(f\"   {path['path_string']}\")\n",
    "            \n",
    "            # Add biomedical context\n",
    "            nodes = path.get(\"nodes\", [])\n",
    "            if nodes:\n",
    "                source_labels = nodes[0].get(\"labels\", [])\n",
    "                target_labels = nodes[-1].get(\"labels\", [])\n",
    "                if source_labels or target_labels:\n",
    "                    output_lines.append(f\"   Context: {source_labels[0] if source_labels else 'Unknown'} â†’ {target_labels[0] if target_labels else 'Unknown'}\")\n",
    "    \n",
    "    return \"\\n\".join(output_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240329a8",
   "metadata": {},
   "source": [
    "# ENHANCED MAIN PIPELINE WITH PATH PRUNING AND COT GENERATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e987257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_map_entities_with_cot(text: str, client) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete enhanced pipeline with property-aware entity mapping, path pruning, and CoT generation.\n",
    "    Biomedical/fertility focused version.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ” Processing clinical question: '{text[:100]}...'\" if len(text) > 100 else f\"\\nðŸ” Processing clinical question: '{text}'\")\n",
    "    \n",
    "    # Step 1: Extract fertility-related biomedical entities from text\n",
    "    print(\"ðŸ“ Extracting fertility-related biomedical entities from text...\")\n",
    "    extracted_entities = extract_entities_from_text(text, client)\n",
    "    print(f\"âœ… Extracted {len(extracted_entities)} clinical entities:\")\n",
    "    for entity in extracted_entities:\n",
    "        conf = entity.get('confidence', 0.7)\n",
    "        entity_type = entity.get('type', 'Unknown')\n",
    "        print(f\"   - {entity['name']} ({entity_type}) [Confidence: {conf:.2f}]\")\n",
    "    \n",
    "    # Step 2: Map each entity to KG with property enhancement\n",
    "    print(\"\\nðŸ—ºï¸  Mapping clinical entities to biomedical knowledge graph...\")\n",
    "    mapped_results = []\n",
    "    \n",
    "    for entity in extracted_entities:\n",
    "        print(f\"  ðŸ”„ Mapping clinical entity: {entity['name']} ({entity.get('type', 'Unknown')})...\")\n",
    "        mapping_result = map_entity_to_kg_with_properties(entity, text, client)\n",
    "        \n",
    "        # Add stage-specific emoji with biomedical context\n",
    "        stage = mapping_result.get(\"mapping_stage\", \"unknown\")\n",
    "        stage_emoji = {\n",
    "            \"property_exact\": \"ðŸŽ¯\",      # Exact property match\n",
    "            \"property_enhanced\": \"ðŸ“Š\",   # Enhanced similarity\n",
    "            \"property_llm\": \"ðŸ¤–\",        # LLM-assisted match\n",
    "            \"property_fallback\": \"âš ï¸\",   # Fallback match\n",
    "            \"no_candidates\": \"âŒ\"        # No match\n",
    "        }.get(stage, \"ðŸ”\")\n",
    "        \n",
    "        if mapping_result[\"mapped_node\"]:\n",
    "            node_info = mapping_result[\"mapped_node\"]\n",
    "            match_type = node_info.get('match_type', 'unknown')\n",
    "            score = node_info.get('enhanced_score', 0)\n",
    "            \n",
    "            # Color code based on confidence\n",
    "            if score >= 0.9:\n",
    "                score_str = f\"\\033[92m{score:.3f}\\033[0m\"  # Green\n",
    "            elif score >= 0.7:\n",
    "                score_str = f\"\\033[93m{score:.3f}\\033[0m\"  # Yellow\n",
    "            else:\n",
    "                score_str = f\"\\033[91m{score:.3f}\\033[0m\"  # Red\n",
    "            \n",
    "            print(f\"    {stage_emoji} {stage}: {entity['name']} â†’ \\033[1m{node_info['node_name']}\\033[0m \"\n",
    "                  f\"(Score: {score_str}, Match: {match_type})\")\n",
    "        else:\n",
    "            print(f\"    {stage_emoji} No biomedical mapping found for {entity['name']}\")\n",
    "        \n",
    "        mapped_results.append(mapping_result)\n",
    "    \n",
    "    # Step 3: Perform biomedical path search between mapped entities\n",
    "    print(\"\\nðŸ›¤ï¸  Searching biomedical pathways between mapped entities...\")\n",
    "    path_results = find_shortest_paths_between_entities(mapped_results)\n",
    "    \n",
    "    # Display path summary immediately\n",
    "    if path_results[\"entity_pairs\"]:\n",
    "        print(f\"âœ… Found paths for {len(path_results['entity_pairs'])} entity pairs\")\n",
    "        for pair in path_results[\"entity_pairs\"][:2]:  # Show first 2 pairs\n",
    "            print(f\"   â€¢ {pair['source_entity']} â†’ {pair['target_entity']}: {pair['paths_found']} paths\")\n",
    "    else:\n",
    "        print(\"âŒ No biomedical pathways found between mapped entities\")\n",
    "    \n",
    "    # Step 4: Prune paths using LLM to select the most clinically relevant one\n",
    "    if path_results[\"all_paths\"]:\n",
    "        print(\"\\nâœ‚ï¸  Selecting most clinically relevant path...\")\n",
    "        path_pruning_result = prune_paths_with_llm(text, path_results[\"all_paths\"], mapped_results, client)\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Skipping path pruning - no paths available\")\n",
    "        path_pruning_result = {\"selected_path\": None, \"reasoning\": \"No paths found\"}\n",
    "    \n",
    "    # Step 5: Generate clinical Chain-of-Thought reasoning\n",
    "    print(\"\\nðŸ§  Generating clinical Chain-of-Thought reasoning...\")\n",
    "    selected_path = path_pruning_result.get(\"selected_path\")\n",
    "    cot_result = generate_chain_of_thought(text, selected_path, mapped_results, client)\n",
    "    \n",
    "    # Display results in clinical format\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLINICAL ANALYSIS RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Display entity mapping summary\n",
    "    print(f\"\\nðŸ“Š Clinical Entity Mapping Summary:\")\n",
    "    successful_mappings = [m for m in mapped_results if m.get(\"mapped_node\")]\n",
    "    total_entities = len(extracted_entities)\n",
    "    \n",
    "    if total_entities > 0:\n",
    "        success_rate = len(successful_mappings) / total_entities * 100\n",
    "        print(f\"   Successfully mapped: {len(successful_mappings)}/{total_entities} entities ({success_rate:.1f}%)\")\n",
    "        \n",
    "        # Show mapping quality distribution\n",
    "        high_confidence = sum(1 for m in successful_mappings \n",
    "                             if m[\"mapped_node\"].get(\"enhanced_score\", 0) >= 0.8)\n",
    "        medium_confidence = sum(1 for m in successful_mappings \n",
    "                               if 0.6 <= m[\"mapped_node\"].get(\"enhanced_score\", 0) < 0.8)\n",
    "        low_confidence = sum(1 for m in successful_mappings \n",
    "                            if m[\"mapped_node\"].get(\"enhanced_score\", 0) < 0.6)\n",
    "        \n",
    "        if successful_mappings:\n",
    "            print(f\"   Mapping confidence levels:\")\n",
    "            print(f\"     â€¢ High (â‰¥0.8): {high_confidence} entities\")\n",
    "            print(f\"     â€¢ Medium (0.6-0.8): {medium_confidence} entities\")\n",
    "            print(f\"     â€¢ Low (<0.6): {low_confidence} entities\")\n",
    "    \n",
    "    # Display path analysis\n",
    "    print(f\"\\nðŸ›¤ï¸  Biomedical Pathway Analysis:\")\n",
    "    if selected_path:\n",
    "        path_desc = selected_path.get('detailed_description', selected_path.get('path_string', 'N/A'))\n",
    "        print(f\"   Selected clinical pathway: {path_desc}\")\n",
    "        print(f\"   Pathway length: {selected_path.get('path_length', 'N/A')} biological relationships\")\n",
    "        \n",
    "        confidence = path_pruning_result.get('confidence', 0)\n",
    "        confidence_color = \"\\033[92m\" if confidence >= 0.8 else \"\\033[93m\" if confidence >= 0.6 else \"\\033[91m\"\n",
    "        print(f\"   Clinical relevance confidence: {confidence_color}{confidence:.2f}\\033[0m\")\n",
    "        \n",
    "        reasoning = path_pruning_result.get('reasoning', 'N/A')\n",
    "        if len(reasoning) > 120:\n",
    "            reasoning = reasoning[:120] + \"...\"\n",
    "        print(f\"   Selection rationale: {reasoning}\")\n",
    "        \n",
    "        # Show fertility relevance if present\n",
    "        fertility_keywords = [\"fertility\", \"infertility\", \"reproductive\", \"ovarian\", \"uterine\", \"sperm\", \"embryo\"]\n",
    "        path_text = json.dumps(selected_path).lower()\n",
    "        fertility_matches = [kw for kw in fertility_keywords if kw in path_text]\n",
    "        if fertility_matches:\n",
    "            print(f\"   Fertility relevance: âœ… (mentions: {', '.join(fertility_matches[:3])})\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  No clinically relevant pathway selected\")\n",
    "    \n",
    "    # Display clinical reasoning\n",
    "    print(f\"\\nðŸ§  Clinical Reasoning Chain:\")\n",
    "    if cot_result and \"chain_of_thought\" in cot_result:\n",
    "        cot = cot_result[\"chain_of_thought\"]\n",
    "        \n",
    "        # Show reasoning steps\n",
    "        steps = cot.get('reasoning_steps', [])\n",
    "        if steps:\n",
    "            print(f\"   Reasoning steps ({len(steps)} total):\")\n",
    "            for i, step in enumerate(steps[:3]):  # Show first 3 steps\n",
    "                step_text = step.replace(\"Step X:\", \"\").replace(\"Step X: \", \"\").strip()\n",
    "                if step_text:\n",
    "                    print(f\"     {i+1}. {step_text[:80]}...\")\n",
    "            if len(steps) > 3:\n",
    "                print(f\"     ... and {len(steps) - 3} more steps\")\n",
    "        \n",
    "        # Show final clinical answer\n",
    "        final_answer = cot.get('final_answer', 'N/A')\n",
    "        print(f\"\\n   ðŸ“‹ Clinical Answer:\")\n",
    "        print(f\"   \\\"{final_answer}\\\"\")\n",
    "        \n",
    "        # Show detailed reasoning preview\n",
    "        detailed_reasoning = cot.get('detailed_reasoning', '')\n",
    "        if detailed_reasoning and len(detailed_reasoning) > 50:\n",
    "            print(f\"\\n   ðŸ” Reasoning preview:\")\n",
    "            # Get first paragraph\n",
    "            first_para = detailed_reasoning.split('\\n\\n')[0]\n",
    "            if len(first_para) > 150:\n",
    "                first_para = first_para[:150] + \"...\"\n",
    "            print(f\"   {first_para}\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  No clinical reasoning generated\")\n",
    "    \n",
    "    # Summary of biomedical knowledge used\n",
    "    print(f\"\\nðŸ“š Biomedical Knowledge Used:\")\n",
    "    print(f\"   â€¢ Knowledge graph nodes: {len(KG_NODES)} (disease/drug only)\")\n",
    "    print(f\"   â€¢ Entity types supported: {', '.join(ENTITY_TYPES)}\")\n",
    "    print(f\"   â€¢ Disease properties: {len(ENTITY_PROPERTY_SCHEMAS.get('disease', {}).get('properties', []))}\")\n",
    "    print(f\"   â€¢ Drug properties: {len(ENTITY_PROPERTY_SCHEMAS.get('drug', {}).get('properties', []))}\")\n",
    "    \n",
    "    # Prepare enhanced output with clinical context\n",
    "    output = {\n",
    "        \"clinical_question\": text,\n",
    "        \"extracted_entities\": extracted_entities,\n",
    "        \"extracted_entities_count\": len(extracted_entities),\n",
    "        \"mapped_entities\": mapped_results,\n",
    "        \"path_search_results\": path_results,\n",
    "        \"path_pruning_result\": path_pruning_result,\n",
    "        \"chain_of_thought\": cot_result,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"clinical_context\": {\n",
    "            \"domain\": \"Fertility/Reproductive Medicine\",\n",
    "            \"biomedical_kg_info\": {\n",
    "                \"total_disease_drug_nodes\": len(KG_NODES),\n",
    "                \"entity_types_focused\": ENTITY_TYPES,\n",
    "                \"property_schemas_used\": list(ENTITY_PROPERTY_SCHEMAS.keys())\n",
    "            },\n",
    "            \"fertility_relevance\": {\n",
    "                \"fertility_keywords_present\": any(kw in text.lower() for kw in \n",
    "                                                  [\"fertility\", \"infertility\", \"reproductive\", \"pregnancy\"]),\n",
    "                \"extracted_fertility_entities\": sum(1 for e in extracted_entities \n",
    "                                                   if any(kw in e['name'].lower() for kw in \n",
    "                                                         [\"pcos\", \"endometriosis\", \"infertility\", \"clomiphene\"]))\n",
    "            }\n",
    "        },\n",
    "        \"pipeline_config\": {\n",
    "            \"top_k\": TOP_K,\n",
    "            \"similarity_threshold\": SIM_THRESHOLD,\n",
    "            \"exact_match_threshold\": EXACT_MATCH_THRESHOLD,\n",
    "            \"property_weights\": PROPERTY_WEIGHTS,\n",
    "            \"max_path_length\": MAX_PATH_LENGTH,\n",
    "            \"max_paths_per_pair\": MAX_PATHS_PER_PAIR,\n",
    "            \"top_paths_for_pruning\": TOP_PATHS_FOR_PRUNING,\n",
    "            \"llm_model\": LLM_MODEL\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43d54d",
   "metadata": {},
   "source": [
    "# PROPERTY ANALYSIS UTILITIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f168a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_property_matches(results: List[Dict]):\n",
    "    \"\"\"Analyze property-based matching performance for biomedical entities.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BIOMEDICAL PROPERTY MATCHING ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_mapped = 0\n",
    "    property_based_matches = 0\n",
    "    stage_distribution = defaultdict(int)\n",
    "    match_type_distribution = defaultdict(int)\n",
    "    entity_type_distribution = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for result in results:\n",
    "        for mapping in result.get(\"mapped_entities\", []):\n",
    "            if mapping.get(\"mapped_node\"):\n",
    "                total_mapped += 1\n",
    "                stage = mapping.get(\"mapping_stage\", \"unknown\")\n",
    "                stage_distribution[stage] += 1\n",
    "                \n",
    "                # Get entity type\n",
    "                entity_type = mapping.get(\"query_entity\", {}).get(\"type\", \"Unknown\")\n",
    "                entity_type_distribution[entity_type][\"total\"] += 1\n",
    "                entity_type_distribution[entity_type][stage] += 1\n",
    "                \n",
    "                # Check if property matching was involved\n",
    "                mapped_node = mapping.get(\"mapped_node\", {})\n",
    "                match_type = mapped_node.get(\"match_type\", \"\")\n",
    "                if match_type and \"property\" in stage.lower() or mapping.get(\"property_info\"):\n",
    "                    property_based_matches += 1\n",
    "                    entity_type_distribution[entity_type][\"property_based\"] += 1\n",
    "                \n",
    "                # Track match types\n",
    "                if match_type:\n",
    "                    match_type_distribution[match_type] += 1\n",
    "    \n",
    "    print(f\"Total clinical entities mapped: {total_mapped}\")\n",
    "    if total_mapped > 0:\n",
    "        prop_percentage = property_based_matches/total_mapped*100 if total_mapped > 0 else 0\n",
    "        print(f\"Biomedical property-based matches: {property_based_matches} ({prop_percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nMapping stage distribution:\")\n",
    "    stage_emojis = {\n",
    "        \"property_exact\": \"ðŸŽ¯\",\n",
    "        \"property_enhanced\": \"ðŸ“Š\",\n",
    "        \"property_llm\": \"ðŸ¤–\",\n",
    "        \"property_fallback\": \"âš ï¸\",\n",
    "        \"no_candidates\": \"âŒ\"\n",
    "    }\n",
    "    for stage, count in sorted(stage_distribution.items()):\n",
    "        emoji = stage_emojis.get(stage, \"ðŸ”\")\n",
    "        percentage = count/total_mapped*100 if total_mapped > 0 else 0\n",
    "        print(f\"  {emoji} {stage}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nBiomedical match type distribution:\")\n",
    "    for match_type, count in sorted(match_type_distribution.items()):\n",
    "        # Group similar match types\n",
    "        if \"exact_\" in match_type:\n",
    "            match_display = \"ðŸ” Exact property matches\"\n",
    "        elif \"contains_\" in match_type:\n",
    "            match_display = \"ðŸ“„ Contains property matches\"\n",
    "        elif \"name\" in match_type:\n",
    "            match_display = \"ðŸ·ï¸  Name matches\"\n",
    "        elif \"property_enhanced\" in match_type:\n",
    "            match_display = \"âš¡ Property-enhanced similarity\"\n",
    "        else:\n",
    "            match_display = f\"â“ {match_type}\"\n",
    "        \n",
    "        print(f\"  {match_display}: {count}\")\n",
    "    \n",
    "    print(f\"\\nEntity type distribution (disease/drug):\")\n",
    "    if total_mapped > 0:\n",
    "        for entity_type, stats in entity_type_distribution.items():\n",
    "            total = stats.get(\"total\", 0)\n",
    "            prop_based = stats.get(\"property_based\", 0)\n",
    "            prop_pct = prop_based/total*100 if total > 0 else 0\n",
    "            \n",
    "            entity_emoji = \"ðŸ¦ \" if entity_type.lower() == \"disease\" else \"ðŸ’Š\" if entity_type.lower() == \"drug\" else \"â“\"\n",
    "            print(f\"  {entity_emoji} {entity_type}: {total} entities\")\n",
    "            print(f\"     Property-based matches: {prop_based} ({prop_pct:.1f}%)\")\n",
    "            \n",
    "            # Show stage distribution for this entity type\n",
    "            for stage, count in stats.items():\n",
    "                if stage not in [\"total\", \"property_based\"] and count > 0:\n",
    "                    stage_emoji = stage_emojis.get(stage, \"ðŸ”\")\n",
    "                    print(f\"     {stage_emoji} {stage}: {count}\")\n",
    "\n",
    "def generate_property_mapping_report(result: Dict):\n",
    "    \"\"\"Generate detailed clinical property mapping report for a single result.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLINICAL PROPERTY MAPPING REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"Clinical Question: {result.get('clinical_question', result.get('text', ''))[:120]}...\")\n",
    "    print(f\"Extracted biomedical entities: {result.get('extracted_entities_count', 0)}\")\n",
    "    \n",
    "    # Check fertility relevance\n",
    "    fertility_context = result.get(\"clinical_context\", {}).get(\"fertility_relevance\", {})\n",
    "    if fertility_context.get(\"fertility_keywords_present\", False):\n",
    "        print(f\"Fertility relevance: âœ… (Keywords detected in question)\")\n",
    "    if fertility_context.get(\"extracted_fertility_entities\", 0) > 0:\n",
    "        print(f\"Fertility entities extracted: {fertility_context['extracted_fertility_entities']}\")\n",
    "    \n",
    "    # Display biomedical mapping details\n",
    "    mapped_entities = result.get(\"mapped_entities\", [])\n",
    "    print(f\"\\nBiomedical Entity Mapping Details:\")\n",
    "    \n",
    "    for i, mapping in enumerate(mapped_entities, 1):\n",
    "        query_entity = mapping.get(\"query_entity\", {})\n",
    "        mapped_node = mapping.get(\"mapped_node\", {})\n",
    "        \n",
    "        # Entity type emoji\n",
    "        entity_type = query_entity.get(\"type\", \"Unknown\")\n",
    "        entity_emoji = \"ðŸ¦ \" if entity_type.lower() == \"disease\" else \"ðŸ’Š\" if entity_type.lower() == \"drug\" else \"â“\"\n",
    "        \n",
    "        print(f\"\\n{i}. {entity_emoji} Clinical Entity: {query_entity.get('name')} ({entity_type})\")\n",
    "        print(f\"   Extraction confidence: {query_entity.get('confidence', 0.7):.2f}\")\n",
    "        \n",
    "        if mapped_node:\n",
    "            # Score color coding\n",
    "            score = mapped_node.get('enhanced_score', 0)\n",
    "            if score >= 0.9:\n",
    "                score_color = \"\\033[92m\"  # Green\n",
    "            elif score >= 0.7:\n",
    "                score_color = \"\\033[93m\"  # Yellow\n",
    "            else:\n",
    "                score_color = \"\\033[91m\"  # Red\n",
    "            \n",
    "            print(f\"   âœ… Mapped to KG: {mapped_node.get('node_name')}\")\n",
    "            print(f\"   Stage: {mapped_node.get('mapping_stage')}\")\n",
    "            print(f\"   Enhanced score: {score_color}{score:.4f}\\033[0m\")\n",
    "            print(f\"   Match type: {mapped_node.get('match_type', 'unknown')}\")\n",
    "            \n",
    "            if \"property_match_type\" in mapped_node:\n",
    "                prop_match = mapped_node['property_match_type']\n",
    "                if \"exact_primary_key\" in prop_match:\n",
    "                    print(f\"   ðŸŽ¯ Property match: {prop_match}\")\n",
    "                elif \"exact_display_property\" in prop_match:\n",
    "                    print(f\"   ðŸ“Š Property match: {prop_match}\")\n",
    "                elif \"contains\" in prop_match:\n",
    "                    print(f\"   ðŸ” Property match: {prop_match}\")\n",
    "            \n",
    "            # Show matched KG node labels\n",
    "            kg_labels = mapped_node.get('labels', [])\n",
    "            if kg_labels:\n",
    "                print(f\"   KG labels: {', '.join(kg_labels)}\")\n",
    "            \n",
    "            # Show fertility relevance if available\n",
    "            if query_entity.get('name', '').lower() in ['pcos', 'endometriosis', 'infertility', 'clomiphene', 'letrozole']:\n",
    "                print(f\"   ðŸ¥ Fertility relevance: High\")\n",
    "        else:\n",
    "            print(f\"   âŒ Not mapped to knowledge graph\")\n",
    "            print(f\"   Stage: {mapping.get('mapping_stage', 'unknown')}\")\n",
    "            print(f\"   Reason: {mapping.get('reason', 'No match found')}\")\n",
    "        \n",
    "        # Detailed property information\n",
    "        property_info = mapping.get(\"property_info\", {})\n",
    "        if property_info:\n",
    "            print(f\"\\n   ðŸ”¬ Biomedical Property Analysis:\")\n",
    "            \n",
    "            # Show match type\n",
    "            match_type = property_info.get(\"match_type\", \"\")\n",
    "            if match_type:\n",
    "                print(f\"     Match type: {match_type}\")\n",
    "            \n",
    "            # Show matched properties\n",
    "            matched_props = property_info.get(\"matched_properties\", [])\n",
    "            if matched_props:\n",
    "                print(f\"     Matched biomedical properties: {', '.join(matched_props[:5])}\")\n",
    "                if len(matched_props) > 5:\n",
    "                    print(f\"     ... and {len(matched_props) - 5} more\")\n",
    "            \n",
    "            # Show specific property matches\n",
    "            matched_property = property_info.get(\"matched_property\")\n",
    "            if matched_property:\n",
    "                print(f\"     Key matched property: {matched_property}\")\n",
    "                prop_value = property_info.get(\"property_value\", \"\")\n",
    "                if prop_value:\n",
    "                    if len(str(prop_value)) > 80:\n",
    "                        prop_value = str(prop_value)[:80] + \"...\"\n",
    "                    print(f\"     Property value: {prop_value}\")\n",
    "            \n",
    "            # Show score breakdown\n",
    "            score_breakdown = property_info.get(\"score_breakdown\", {})\n",
    "            if score_breakdown:\n",
    "                print(f\"     Score breakdown:\")\n",
    "                for key, value in score_breakdown.items():\n",
    "                    if isinstance(value, float):\n",
    "                        print(f\"       â€¢ {key}: {value:.3f}\")\n",
    "                    else:\n",
    "                        print(f\"       â€¢ {key}: {value}\")\n",
    "    \n",
    "    # Path analysis section\n",
    "    path_pruning = result.get(\"path_pruning_result\", {})\n",
    "    if path_pruning.get(\"selected_path\"):\n",
    "        print(f\"\\nðŸ›¤ï¸  Selected Biomedical Pathway:\")\n",
    "        selected_path = path_pruning[\"selected_path\"]\n",
    "        print(f\"   Pathway: {selected_path.get('detailed_description', selected_path.get('path_string', ''))}\")\n",
    "        print(f\"   Length: {selected_path.get('path_length', 'N/A')} biological relationships\")\n",
    "        print(f\"   Selection confidence: {path_pruning.get('confidence', 0):.2f}\")\n",
    "        \n",
    "        # Show entities in path\n",
    "        nodes = selected_path.get(\"nodes\", [])\n",
    "        if nodes:\n",
    "            print(f\"   Entities in pathway:\")\n",
    "            for j, node in enumerate(nodes[:3]):  # Show first 3\n",
    "                node_labels = node.get(\"labels\", [])\n",
    "                label_str = node_labels[0] if node_labels else \"Unknown\"\n",
    "                print(f\"     {j+1}. {node.get('name', 'Unknown')} ({label_str})\")\n",
    "            if len(nodes) > 3:\n",
    "                print(f\"     ... and {len(nodes) - 3} more\")\n",
    "    \n",
    "    # Clinical reasoning summary\n",
    "    cot_result = result.get(\"chain_of_thought\", {})\n",
    "    if cot_result and \"chain_of_thought\" in cot_result:\n",
    "        cot = cot_result[\"chain_of_thought\"]\n",
    "        print(f\"\\nðŸ§  Clinical Reasoning Summary:\")\n",
    "        print(f\"   Final clinical answer: {cot.get('final_answer', 'N/A')}\")\n",
    "        \n",
    "        steps = cot.get('reasoning_steps', [])\n",
    "        if steps and len(steps) > 0:\n",
    "            print(f\"   First reasoning step: {steps[0][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b876f30",
   "metadata": {},
   "source": [
    "# ENHANCED DEMO WITH PATH PRUNING AND COT GENERATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77333240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline_demo(client):\n",
    "    \"\"\"Run complete clinical pipeline with entity extraction, mapping, path pruning, and CoT generation.\"\"\"\n",
    "    \n",
    "    # Test cases with clinical questions that benefit from path analysis\n",
    "    test_cases = [\n",
    "        \"Is Clomiphene citrate effective for PCOS?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLINICAL BIOMEDICAL PIPELINE WITH PATH PRUNING & COT GENERATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ðŸ”¬ Using {len(KG_NODES)} disease/drug KG nodes with biomedical property-aware matching\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, text in enumerate(test_cases, 1):\n",
    "        print(f\"\\nðŸ“‹ CLINICAL TEST CASE {i}:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        result = extract_and_map_entities_with_cot(text, client)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Quick clinical summary\n",
    "        print(f\"\\nðŸ“Š Clinical Summary for Test {i}:\")\n",
    "        print(f\"   Clinical Question: {text}\")\n",
    "        print(f\"   Biomedical entities extracted: {result['extracted_entities_count']}\")\n",
    "        \n",
    "        # Show specific entities if extracted\n",
    "        entities = result.get('extracted_entities', [])\n",
    "        if entities:\n",
    "            entity_types = []\n",
    "            for entity in entities[:3]:  # Show first 3\n",
    "                entity_type = entity.get('type', 'Unknown')\n",
    "                entity_emoji = \"ðŸ¦ \" if entity_type.lower() == \"disease\" else \"ðŸ’Š\" if entity_type.lower() == \"drug\" else \"â“\"\n",
    "                entity_types.append(f\"{entity_emoji} {entity['name']}\")\n",
    "            if len(entities) > 3:\n",
    "                entity_types.append(f\"... +{len(entities)-3} more\")\n",
    "            print(f\"   Extracted entities: {', '.join(entity_types)}\")\n",
    "        \n",
    "        print(f\"   Biomedical pathways found: {result['path_search_results']['total_paths_found']}\")\n",
    "        \n",
    "        # Show selected pathway\n",
    "        if result.get('path_pruning_result', {}).get('selected_path'):\n",
    "            selected_path = result['path_pruning_result']['selected_path']\n",
    "            path_desc = selected_path.get('detailed_description', selected_path.get('path_string', 'N/A'))\n",
    "            if len(path_desc) > 120:\n",
    "                path_desc = path_desc[:120] + \"...\"\n",
    "            print(f\"   Selected clinical pathway: {path_desc}\")\n",
    "            confidence = result['path_pruning_result'].get('confidence', 0)\n",
    "            \n",
    "            # Color code confidence\n",
    "            if confidence >= 0.8:\n",
    "                conf_color = \"\\033[92m\"  # Green\n",
    "            elif confidence >= 0.6:\n",
    "                conf_color = \"\\033[93m\"  # Yellow\n",
    "            else:\n",
    "                conf_color = \"\\033[91m\"  # Red\n",
    "            print(f\"   Pathway relevance confidence: {conf_color}{confidence:.2f}\\033[0m\")\n",
    "        \n",
    "        # Show final clinical answer\n",
    "        cot_data = result.get('chain_of_thought', {}).get('chain_of_thought', {})\n",
    "        if cot_data and cot_data.get('final_answer'):\n",
    "            answer = cot_data['final_answer']\n",
    "            print(f\"   ðŸ“‹ Clinical Answer: \\\"{answer}\\\"\")\n",
    "            \n",
    "            # Show reasoning step count\n",
    "            steps = cot_data.get('reasoning_steps', [])\n",
    "            if steps:\n",
    "                print(f\"   Reasoning steps: {len(steps)}\")\n",
    "        \n",
    "        # Show fertility relevance if present\n",
    "        fertility_ctx = result.get('clinical_context', {}).get('fertility_relevance', {})\n",
    "        if fertility_ctx.get('fertility_keywords_present', False):\n",
    "            print(f\"   ðŸ¥ Fertility context detected\")\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"CLINICAL PIPELINE DEMO COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_questions = len(all_results)\n",
    "    total_entities = sum(r.get('extracted_entities_count', 0) for r in all_results)\n",
    "    total_paths = sum(r.get('path_search_results', {}).get('total_paths_found', 0) for r in all_results)\n",
    "    questions_with_paths = sum(1 for r in all_results \n",
    "                              if r.get('path_search_results', {}).get('total_paths_found', 0) > 0)\n",
    "    questions_with_answers = sum(1 for r in all_results \n",
    "                                if r.get('chain_of_thought', {}).get('chain_of_thought', {}).get('final_answer'))\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Overall Clinical Performance:\")\n",
    "    print(f\"   Clinical questions analyzed: {total_questions}\")\n",
    "    print(f\"   Total biomedical entities extracted: {total_entities}\")\n",
    "    print(f\"   Total biomedical pathways found: {total_paths}\")\n",
    "    print(f\"   Questions with pathways: {questions_with_paths}/{total_questions} ({questions_with_paths/total_questions*100:.1f}%)\")\n",
    "    print(f\"   Questions answered: {questions_with_answers}/{total_questions} ({questions_with_answers/total_questions*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze entity type distribution\n",
    "    disease_count = 0\n",
    "    drug_count = 0\n",
    "    for result in all_results:\n",
    "        for entity in result.get('extracted_entities', []):\n",
    "            entity_type = entity.get('type', '').lower()\n",
    "            if entity_type == 'disease':\n",
    "                disease_count += 1\n",
    "            elif entity_type == 'drug':\n",
    "                drug_count += 1\n",
    "    \n",
    "    if total_entities > 0:\n",
    "        print(f\"\\nðŸ§¬ Biomedical Entity Distribution:\")\n",
    "        print(f\"   ðŸ¦  Diseases: {disease_count} ({disease_count/total_entities*100:.1f}%)\")\n",
    "        print(f\"   ðŸ’Š Drugs: {drug_count} ({drug_count/total_entities*100:.1f}%)\")\n",
    "    \n",
    "    # Run property matching analysis\n",
    "    if all_results:\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        analyze_property_matches(all_results)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeea38ad",
   "metadata": {},
   "source": [
    "# MAIN EXECUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa5cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¬ Loading biomedical sentence transformer model...\n",
      "âœ… Embedding model loaded\n",
      "\n",
      "ðŸ§¬ Generating biomedical embeddings for knowledge graph nodes...\n",
      "âœ… Generated embeddings for 25037 disease/drug nodes\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "try:\n",
    "    print(\"ðŸ§¬ Loading biomedical sentence transformer model...\")\n",
    "    embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    print(\"âœ… Embedding model loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading embedding model: {e}\")\n",
    "    exit(1)\n",
    "    \n",
    "    # Generate embeddings for all KG nodes\n",
    "print(\"\\nðŸ§¬ Generating biomedical embeddings for knowledge graph nodes...\")\n",
    "KG_EMBEDDINGS = embedder.encode(KG_TEXTS)\n",
    "print(f\"âœ… Generated embeddings for {len(KG_EMBEDDINGS)} disease/drug nodes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6388fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Groq client initialized for clinical reasoning\n",
      "\n",
      "================================================================================\n",
      "ðŸš€ STARTING COMPLETE CLINICAL PIPELINE DEMO\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CLINICAL BIOMEDICAL PIPELINE WITH PATH PRUNING & COT GENERATION\n",
      "================================================================================\n",
      "ðŸ”¬ Using 25037 disease/drug KG nodes with biomedical property-aware matching\n",
      "\n",
      "\n",
      "ðŸ“‹ CLINICAL TEST CASE 1:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ” Processing clinical question: 'Is Clomiphene citrate effective for PCOS?'\n",
      "ðŸ“ Extracting fertility-related biomedical entities from text...\n",
      "âœ… Extracted 2 clinical entities:\n",
      "   - PCOS (disease) [Confidence: 0.90]\n",
      "   - Clomiphene citrate (drug) [Confidence: 0.95]\n",
      "\n",
      "ðŸ—ºï¸  Mapping clinical entities to biomedical knowledge graph...\n",
      "  ðŸ”„ Mapping clinical entity: PCOS (disease)...\n",
      "    ðŸ” unknown: PCOS â†’ \u001b[1mpolycystic ovary syndrome\u001b[0m (Score: \u001b[91m0.388\u001b[0m, Match: property_enhanced)\n",
      "  ðŸ”„ Mapping clinical entity: Clomiphene citrate (drug)...\n",
      "    ðŸ” unknown: Clomiphene citrate â†’ \u001b[1mClomifene\u001b[0m (Score: \u001b[91m0.236\u001b[0m, Match: text_similarity_only)\n",
      "\n",
      "ðŸ›¤ï¸  Searching biomedical pathways between mapped entities...\n",
      "\n",
      "ðŸ” Searching paths between 2 mapped biomedical entities...\n",
      "  ðŸ”— PCOS (disease) â†’ Clomiphene citrate (drug)...\n",
      "    âœ… Found 13 paths (showing 5)\n",
      "       â€¢ The exact cause of PCOS isn't known. Factors that might play a role include: Excess insulin. Insulin... --[contraindication]--> The chemical and functional group of  is ovulation stimulants, synthetic.\n",
      "       â€¢ The exact cause of PCOS isn't known. Factors that might play a role include: Excess insulin. Insulin... --[off-label use]--> The chemical and functional group of  is progestogens and estrogens, fixed combinations and progesto... --[drug_drug]--> The chemical and functional group of  is ovulation stimulants, synthetic.\n",
      "âœ… Found paths for 1 entity pairs\n",
      "   â€¢ PCOS â†’ Clomiphene citrate: 13 paths\n",
      "\n",
      "âœ‚ï¸  Selecting most clinically relevant path...\n",
      "\n",
      "ðŸ§  Generating clinical Chain-of-Thought reasoning...\n",
      "\n",
      "================================================================================\n",
      "CLINICAL ANALYSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Clinical Entity Mapping Summary:\n",
      "   Successfully mapped: 2/2 entities (100.0%)\n",
      "   Mapping confidence levels:\n",
      "     â€¢ High (â‰¥0.8): 0 entities\n",
      "     â€¢ Medium (0.6-0.8): 0 entities\n",
      "     â€¢ Low (<0.6): 2 entities\n",
      "\n",
      "ðŸ›¤ï¸  Biomedical Pathway Analysis:\n",
      "   Selected clinical pathway: The exact cause of PCOS isn't known. Factors that might play a role include: Excess insulin. Insulin... (disease) off-label use â†’ Estradiol valerate is part of Adrenal Cortex Hormones ; BCRP/ABCG2 Inhibitors ; Contraceptive Agents... (drug) drug drug â†’ The chemical and functional group of  is sulfonamides and protein kinase inhibitors. (drug) drug drug â†’ The chemical and functional group of  is ovulation stimulants, synthetic. (drug)\n",
      "   Pathway length: 3 biological relationships\n",
      "   Clinical relevance confidence: \u001b[92m1.27\u001b[0m\n",
      "   Selection rationale: Fallback: Selected path with best entity coverage (0/2), biomedical relevance (4), and length 3\n",
      "\n",
      "ðŸ§  Clinical Reasoning Chain:\n",
      "   Reasoning steps (5 total):\n",
      "     1. Step 1: Identified clinical entities in question: PCOS, Clomiphene citrate...\n",
      "     2. Step 2: Found biomedical knowledge graph path connecting Unknown to Unknown...\n",
      "     3. Step 3: Path length: 3 biological relationships...\n",
      "     ... and 2 more steps\n",
      "\n",
      "   ðŸ“‹ Clinical Answer:\n",
      "   \"Yes, Unknown is biologically connected to Unknown in the knowledge graph.\"\n",
      "\n",
      "   ðŸ” Reasoning preview:\n",
      "   Analyzing the biomedical path: The exact cause of PCOS isn't known. Factors that might play a role include: Excess insulin. Insulin... (disease) off-l...\n",
      "\n",
      "ðŸ“š Biomedical Knowledge Used:\n",
      "   â€¢ Knowledge graph nodes: 25037 (disease/drug only)\n",
      "   â€¢ Entity types supported: disease, drug\n",
      "   â€¢ Disease properties: 18\n",
      "   â€¢ Drug properties: 18\n",
      "\n",
      "ðŸ“Š Clinical Summary for Test 1:\n",
      "   Clinical Question: Is Clomiphene citrate effective for PCOS?\n",
      "   Biomedical entities extracted: 2\n",
      "   Extracted entities: ðŸ¦  PCOS, ðŸ’Š Clomiphene citrate\n",
      "   Biomedical pathways found: 13\n",
      "   Selected clinical pathway: The exact cause of PCOS isn't known. Factors that might play a role include: Excess insulin. Insulin... (disease) off-la...\n",
      "   Pathway relevance confidence: \u001b[92m1.27\u001b[0m\n",
      "   ðŸ“‹ Clinical Answer: \"Yes, Unknown is biologically connected to Unknown in the knowledge graph.\"\n",
      "   Reasoning steps: 5\n",
      "\n",
      "================================================================================\n",
      "CLINICAL PIPELINE DEMO COMPLETE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ˆ Overall Clinical Performance:\n",
      "   Clinical questions analyzed: 1\n",
      "   Total biomedical entities extracted: 2\n",
      "   Total biomedical pathways found: 13\n",
      "   Questions with pathways: 1/1 (100.0%)\n",
      "   Questions answered: 1/1 (100.0%)\n",
      "\n",
      "ðŸ§¬ Biomedical Entity Distribution:\n",
      "   ðŸ¦  Diseases: 1 (50.0%)\n",
      "   ðŸ’Š Drugs: 1 (50.0%)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      "BIOMEDICAL PROPERTY MATCHING ANALYSIS\n",
      "======================================================================\n",
      "Total clinical entities mapped: 2\n",
      "Biomedical property-based matches: 2 (100.0%)\n",
      "\n",
      "Mapping stage distribution:\n",
      "  ðŸ” unknown: 2 (100.0%)\n",
      "\n",
      "Biomedical match type distribution:\n",
      "  âš¡ Property-enhanced similarity: 1\n",
      "  â“ text_similarity_only: 1\n",
      "\n",
      "Entity type distribution (disease/drug):\n",
      "  ðŸ¦  disease: 1 entities\n",
      "     Property-based matches: 1 (100.0%)\n",
      "     ðŸ” unknown: 1\n",
      "  ðŸ’Š drug: 1 entities\n",
      "     Property-based matches: 1 (100.0%)\n",
      "     ðŸ” unknown: 1\n",
      "\n",
      "ðŸ’¾ Clinical results saved to 'clinical_pipeline_results.json'\n",
      "\n",
      "================================================================================\n",
      "SAMPLE CLINICAL CHAIN-OF-THOUGHT OUTPUT\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Clinical Question: Is Clomiphene citrate effective for PCOS?\n",
      "\n",
      "ðŸ¥ Final Clinical Answer: Yes, Unknown is biologically connected to Unknown in the knowledge graph.\n",
      "\n",
      "ðŸ§  Clinical Reasoning Steps (5 total):\n",
      "\n",
      "1. Step 1: Identified clinical entities in question: PCOS, Clomiphene citrate\n",
      "\n",
      "2. Step 2: Found biomedical knowledge graph path connecting Unknown to Unknown\n",
      "\n",
      "3. Step 3: Path length: 3 biological relationships\n",
      "\n",
      "4. Step 4: The path shows that Unknown is biologically connected to Unknown\n",
      "\n",
      "5. Step 5: Based on this biomedical connection, we can answer the clinical question\n",
      "\n",
      "ðŸ” Detailed Clinical Reasoning Preview:\n",
      "   Analyzing the biomedical path: The exact cause of PCOS isn't known. Factors that might play a role include: Excess insul...\n",
      "\n",
      "================================================================================\n",
      "CLINICAL PERFORMANCE REPORT\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Clinical Pipeline Statistics:\n",
      "   Total test cases: 1\n",
      "   Fertility-related questions: 0/1 (0.0%)\n",
      "   Total biomedical entities mapped: 2\n",
      "   High-confidence mappings (â‰¥0.8): 0/2 (0.0%)\n",
      "\n",
      "ðŸ“š Biomedical Knowledge Graph Statistics:\n",
      "   Disease/drug nodes loaded: 25037\n",
      "   Disease nodes: 17080 (68.2%)\n",
      "   Drug nodes: 7957 (31.8%)\n",
      "\n",
      "ðŸ”¬ Biomedical Property Schemas:\n",
      "   DISEASE: 18 properties, Primary keys: node_id, node_name\n",
      "   DRUG: 18 properties, Primary keys: node_id, node_name\n",
      "\n",
      "ðŸŽ‰ Clinical pipeline execution complete!\n",
      "   Date: 2026-01-23 08:34:02\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize Groq client for LLM\n",
    "    try:\n",
    "        from groq import Groq\n",
    "        client = Groq(api_key=\"groq_api\")\n",
    "        print(\"âœ… Groq client initialized for clinical reasoning\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ Groq client not available. Using mock client for testing.\")\n",
    "        class MockClient:\n",
    "            class chat:\n",
    "                class completions:\n",
    "                    @staticmethod\n",
    "                    def create(**kwargs):\n",
    "                        class MockResponse:\n",
    "                            class Choice:\n",
    "                                class Message:\n",
    "                                    content = '{\"Entity\": [{\"id\": \"1\", \"type\": \"disease\", \"name\": \"Polycystic ovary syndrome\", \"confidence\": 0.9}, {\"id\": \"2\", \"type\": \"drug\", \"name\": \"Metformin\", \"confidence\": 0.8}]}'\n",
    "                                message = Message()\n",
    "                            choices = [Choice()]\n",
    "                        return MockResponse()\n",
    "        client = MockClient()\n",
    "    \n",
    "    \n",
    "    # Run complete clinical pipeline demo\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸš€ STARTING COMPLETE CLINICAL PIPELINE DEMO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = run_complete_pipeline_demo(client)\n",
    "    \n",
    "    # Save detailed clinical results\n",
    "    if results:\n",
    "        output_file = \"clinical_pipeline_results.json\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results[0], f, indent=2, default=str, ensure_ascii=False)\n",
    "        print(f\"\\nðŸ’¾ Clinical results saved to '{output_file}'\")\n",
    "        \n",
    "        # Display sample clinical CoT from first result\n",
    "        if results[0].get('chain_of_thought', {}).get('chain_of_thought'):\n",
    "            cot = results[0]['chain_of_thought']['chain_of_thought']\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"SAMPLE CLINICAL CHAIN-OF-THOUGHT OUTPUT\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Display clinical question\n",
    "            clinical_question = results[0].get('clinical_question', results[0].get('text', 'Unknown'))\n",
    "            print(f\"\\nðŸ“‹ Clinical Question: {clinical_question}\")\n",
    "            \n",
    "            # Display final clinical answer\n",
    "            final_answer = cot.get('final_answer', 'N/A')\n",
    "            print(f\"\\nðŸ¥ Final Clinical Answer: {final_answer}\")\n",
    "            \n",
    "            # Display reasoning steps\n",
    "            steps = cot.get('reasoning_steps', [])\n",
    "            if steps:\n",
    "                print(f\"\\nðŸ§  Clinical Reasoning Steps ({len(steps)} total):\")\n",
    "                for i, step in enumerate(steps):\n",
    "                    # Clean up step text\n",
    "                    step_text = step.replace(\"Step X:\", \"\").replace(\"Step X: \", \"\").strip()\n",
    "                    if step_text:\n",
    "                        print(f\"\\n{i+1}. {step_text}\")\n",
    "            \n",
    "            # Display detailed reasoning preview\n",
    "            detailed = cot.get('detailed_reasoning', '')\n",
    "            if detailed:\n",
    "                print(f\"\\nðŸ” Detailed Clinical Reasoning Preview:\")\n",
    "                paragraphs = detailed.split('\\n\\n')\n",
    "                for para in paragraphs[:2]:  # Show first 2 paragraphs\n",
    "                    if para.strip():\n",
    "                        if len(para) > 120:\n",
    "                            para = para[:120] + \"...\"\n",
    "                        print(f\"   {para}\")\n",
    "                if len(paragraphs) > 2:\n",
    "                    print(f\"   ... and {len(paragraphs) - 2} more paragraphs\")\n",
    "        \n",
    "        # Generate comprehensive clinical report\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"CLINICAL PERFORMANCE REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_entities_mapped = 0\n",
    "        high_confidence_mappings = 0\n",
    "        fertility_questions = 0\n",
    "        \n",
    "        for result in results:\n",
    "            # Count mapped entities\n",
    "            for mapping in result.get('mapped_entities', []):\n",
    "                if mapping.get('mapped_node'):\n",
    "                    total_entities_mapped += 1\n",
    "                    if mapping['mapped_node'].get('enhanced_score', 0) >= 0.8:\n",
    "                        high_confidence_mappings += 1\n",
    "            \n",
    "            # Count fertility questions\n",
    "            fertility_ctx = result.get('clinical_context', {}).get('fertility_relevance', {})\n",
    "            if fertility_ctx.get('fertility_keywords_present', False):\n",
    "                fertility_questions += 1\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Clinical Pipeline Statistics:\")\n",
    "        print(f\"   Total test cases: {len(results)}\")\n",
    "        print(f\"   Fertility-related questions: {fertility_questions}/{len(results)} ({fertility_questions/len(results)*100:.1f}%)\")\n",
    "        print(f\"   Total biomedical entities mapped: {total_entities_mapped}\")\n",
    "        \n",
    "        if total_entities_mapped > 0:\n",
    "            high_conf_pct = high_confidence_mappings/total_entities_mapped*100\n",
    "            print(f\"   High-confidence mappings (â‰¥0.8): {high_confidence_mappings}/{total_entities_mapped} ({high_conf_pct:.1f}%)\")\n",
    "        \n",
    "        # Show KG statistics\n",
    "        print(f\"\\nðŸ“š Biomedical Knowledge Graph Statistics:\")\n",
    "        print(f\"   Disease/drug nodes loaded: {len(KG_NODES)}\")\n",
    "        \n",
    "        # Count disease vs drug nodes\n",
    "        disease_nodes = sum(1 for node in KG_NODES if node.get('entity_type') == 'disease')\n",
    "        drug_nodes = sum(1 for node in KG_NODES if node.get('entity_type') == 'drug')\n",
    "        print(f\"   Disease nodes: {disease_nodes} ({disease_nodes/len(KG_NODES)*100:.1f}%)\")\n",
    "        print(f\"   Drug nodes: {drug_nodes} ({drug_nodes/len(KG_NODES)*100:.1f}%)\")\n",
    "        \n",
    "        # Property schema information\n",
    "        print(f\"\\nðŸ”¬ Biomedical Property Schemas:\")\n",
    "        for entity_type, schema in ENTITY_PROPERTY_SCHEMAS.items():\n",
    "            prop_count = len(schema.get('properties', []))\n",
    "            primary_keys = schema.get('primary_keys', [])\n",
    "            print(f\"   {entity_type.upper()}: {prop_count} properties, Primary keys: {', '.join(primary_keys)}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Clinical pipeline execution complete!\")\n",
    "    print(f\"   Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15887415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
